{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1174cb",
   "metadata": {},
   "source": [
    "# Single Path One-Shot Neural Architecture Search using Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368eef94",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63906da",
   "metadata": {},
   "source": [
    "Your task is to implement SPOS + Random Search to find the optimal ResNet-18-like architecture\n",
    "for image classification on CIFAR-10 dataset.\n",
    "\n",
    "### Proposed search space\n",
    "The same search space as in the lecture, but without kernel size search.\n",
    "This means that each search block should only have 3 operations.\n",
    "\n",
    "### Latency awareness\n",
    "While searching, you should implement hard constraint on model latency. As a proxy for\n",
    "latency, use the number of MACs. The baseline ResNet-18 has 37M MACs for images of size 32x32.\n",
    "The final selected architecture should have at most 30M MACs.\n",
    "You can find an example computation for the number of MACs in this notebook.\n",
    "\n",
    "### How to complete the task\n",
    "Plan for your experiments:\n",
    "1. Train baseline ResNet-18 model.  **(2 pts)**\n",
    "2. Finalize supernet code. **(15 pts)**\n",
    "3. Train supernet with the same hyperparameters except the number of epochs. You should increase\n",
    "   it by a factor of 3-6. Save supernet weights.  **(10 pts)**\n",
    "4. Write implementation for Random Search.  **(10 pts)**\n",
    "5. Run it for 100-1000 iterations by measuring accuracies of models from the supernet.\n",
    "   Keep track of each model accuracy and latency.  **(5 pts)**\n",
    "6. Train the best architecture from scratch. For this, you can build the whole supernet, and\n",
    "   select this architecture for all the forward passes of the training.  **(6 pts)**\n",
    "7. Compare with the model from step 1. Does your model have a better accuracy?  **(2 pts)**\n",
    "\n",
    "### Code structure\n",
    "\n",
    "Main.ipynb - Learn your neural networks here.\n",
    "\n",
    "resnet.py - ResNet-18 implementation from torchvision, simplified for this project.\n",
    "\n",
    "supernet.py - Unfinished Supernet implementation.\n",
    "\n",
    "cifar10.py - Transforms for CIFAR-10 training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b67ad",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0fd3f",
   "metadata": {},
   "source": [
    "Before you begin, make sure to install torch, torchvision, numpy, thop and tqdm libraries."
   ]
  },
  {
   "cell_type": "code",
   "id": "4b276c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:11.339455Z",
     "start_time": "2025-03-12T08:50:09.671103Z"
    }
   },
   "source": [
    "!pip install torch torchvision numpy thop tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: torch in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (2.4.1)\r\n",
      "Requirement already satisfied: torchvision in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (0.19.1)\r\n",
      "Requirement already satisfied: numpy in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (1.24.4)\r\n",
      "Requirement already satisfied: thop in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (0.1.1.post2209072238)\r\n",
      "Requirement already satisfied: tqdm in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (2024.9.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torch) (3.0.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from torchvision) (10.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "d45e2d25",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4ba7167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:11.346032Z",
     "start_time": "2025-03-12T08:50:11.341652Z"
    }
   },
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from thop import profile\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cifar10 import get_train_transform, get_val_transform\n",
    "from resnet import resnet18"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "11c9e40b",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "code",
   "id": "32970714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:11.349998Z",
     "start_time": "2025-03-12T08:50:11.347229Z"
    }
   },
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "429fa228",
   "metadata": {},
   "source": [
    "### Build datasets and dataloaders for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "id": "b92e57ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:11.353412Z",
     "start_time": "2025-03-12T08:50:11.351988Z"
    }
   },
   "source": [
    "# Change this value if needed.\n",
    "batch_size = 2048"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "0aed8f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.336145Z",
     "start_time": "2025-03-12T08:50:11.353973Z"
    }
   },
   "source": [
    "train_transform = get_train_transform()\n",
    "val_transform = get_val_transform()\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "cc7a2e7e",
   "metadata": {},
   "source": [
    "## Create your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "id": "7769c967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.338777Z",
     "start_time": "2025-03-12T08:50:12.336949Z"
    }
   },
   "source": [
    "# Select suitable device.\n",
    "# You should probably use either cuda (NVidia GPU) or mps (Apple) backend.\n",
    "device = torch.device('cuda:0')"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "404e7019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.434260Z",
     "start_time": "2025-03-12T08:50:12.339413Z"
    }
   },
   "source": [
    "model = resnet18(num_classes=10, zero_init_residual=True)\n",
    "model.to(device=device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "56e78f87",
   "metadata": {},
   "source": [
    "### Compute the number of MACs and parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "df5abcb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.445148Z",
     "start_time": "2025-03-12T08:50:12.435049Z"
    }
   },
   "source": [
    "macs, params = profile(model, inputs=(torch.zeros(1, 3, 32, 32, device=device),))\n",
    "print(f'Number of macs: {macs / 1e6:.2f}M, number of parameters: {params / 1e6:.2f}M')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Number of macs: 37.22M, number of parameters: 11.18M\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "c91b63ff",
   "metadata": {},
   "source": [
    "## Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d28bd",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "id": "adb69e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.447738Z",
     "start_time": "2025-03-12T08:50:12.445791Z"
    }
   },
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "31a17ef6",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "c73bcfa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.451280Z",
     "start_time": "2025-03-12T08:50:12.449319Z"
    }
   },
   "source": [
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 20  # Longer training gives better results, but let's keep baseline model epochs to 20."
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "365a88db",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "id": "701d2df3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.454037Z",
     "start_time": "2025-03-12T08:50:12.451899Z"
    }
   },
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "d01dec24",
   "metadata": {},
   "source": [
    "### Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc6e0b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:50:12.461069Z",
     "start_time": "2025-03-12T08:50:12.454688Z"
    }
   },
   "source": [
    "def train_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(f'(val) Epoch={epoch}, loss={total_loss / (i + 1):.3f}')\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "15c3ea7d",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "id": "682721bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.292906Z",
     "start_time": "2025-03-12T08:50:12.461739Z"
    }
   },
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch(model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2485 loss=2.315: 100%|██████████| 24/24 [00:03<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3150, train_accuracy=16.343%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=0, loss=2.219: 100%|██████████| 5/5 [00:00<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.2189, test_accuracy=20.890%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=1, lr=0.2439 loss=1.923: 100%|██████████| 24/24 [00:02<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.9226, train_accuracy=27.901%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=1.632: 100%|██████████| 5/5 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6321, test_accuracy=40.140%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=2, lr=0.2364 loss=1.597: 100%|██████████| 24/24 [00:02<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5967, train_accuracy=40.381%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=2, loss=1.467: 100%|██████████| 5/5 [00:00<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4669, test_accuracy=45.680%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=3, lr=0.2261 loss=1.434: 100%|██████████| 24/24 [00:02<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4338, train_accuracy=47.534%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=3, loss=1.294: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.2935, test_accuracy=52.790%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=4, lr=0.2134 loss=1.302: 100%|██████████| 24/24 [00:02<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3018, train_accuracy=52.435%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=1.237: 100%|██████████| 5/5 [00:00<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.2370, test_accuracy=55.800%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=5, lr=0.1985 loss=1.192: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.1918, train_accuracy=56.999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=1.184: 100%|██████████| 5/5 [00:00<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.1841, test_accuracy=57.190%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=6, lr=0.1817 loss=1.106: 100%|██████████| 24/24 [00:02<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.1062, train_accuracy=60.156%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=1.005: 100%|██████████| 5/5 [00:00<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.0054, test_accuracy=63.880%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=7, lr=0.1636 loss=1.027: 100%|██████████| 24/24 [00:02<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.0265, train_accuracy=63.263%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=0.992: 100%|██████████| 5/5 [00:00<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9924, test_accuracy=64.660%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=8, lr=0.1446 loss=0.958: 100%|██████████| 24/24 [00:02<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9580, train_accuracy=65.535%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=0.995: 100%|██████████| 5/5 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9955, test_accuracy=65.600%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.1250 loss=0.905: 100%|██████████| 24/24 [00:02<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9053, train_accuracy=67.981%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=0.894: 100%|██████████| 5/5 [00:00<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8940, test_accuracy=68.650%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=10, lr=0.1054 loss=0.857: 100%|██████████| 24/24 [00:02<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8569, train_accuracy=69.688%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=0.873: 100%|██████████| 5/5 [00:00<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8725, test_accuracy=69.460%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=11, lr=0.0864 loss=0.820: 100%|██████████| 24/24 [00:02<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8199, train_accuracy=70.827%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=11, loss=0.808: 100%|██████████| 5/5 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8079, test_accuracy=71.920%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=12, lr=0.0683 loss=0.784: 100%|██████████| 24/24 [00:02<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7839, train_accuracy=72.133%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=12, loss=0.772: 100%|██████████| 5/5 [00:00<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7721, test_accuracy=73.200%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.0515 loss=0.752: 100%|██████████| 24/24 [00:02<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7519, train_accuracy=73.381%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=13, loss=0.777: 100%|██████████| 5/5 [00:00<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7774, test_accuracy=72.910%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=14, lr=0.0366 loss=0.723: 100%|██████████| 24/24 [00:03<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7228, train_accuracy=74.445%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=0.723: 100%|██████████| 5/5 [00:00<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7227, test_accuracy=74.930%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.0239 loss=0.700: 100%|██████████| 24/24 [00:02<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7001, train_accuracy=75.244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=0.713: 100%|██████████| 5/5 [00:00<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7134, test_accuracy=75.380%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=16, lr=0.0136 loss=0.686: 100%|██████████| 24/24 [00:03<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6860, train_accuracy=75.789%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=0.700: 100%|██████████| 5/5 [00:00<00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7000, test_accuracy=75.790%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=17, lr=0.0061 loss=0.667: 100%|██████████| 24/24 [00:02<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6672, train_accuracy=76.259%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=0.687: 100%|██████████| 5/5 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6873, test_accuracy=76.130%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.0015 loss=0.662: 100%|██████████| 24/24 [00:02<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6623, train_accuracy=76.562%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=18, loss=0.683: 100%|██████████| 5/5 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6828, test_accuracy=76.320%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.0000 loss=0.656: 100%|██████████| 24/24 [00:02<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6564, train_accuracy=76.910%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=19, loss=0.681: 100%|██████████| 5/5 [00:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6811, test_accuracy=76.380%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "2c95733e",
   "metadata": {},
   "source": [
    "### Save trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "id": "a77290d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.366877Z",
     "start_time": "2025-03-12T08:51:25.293762Z"
    }
   },
   "source": [
    "torch.save(model.state_dict(), 'baseline_model.pth')"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "1262a062",
   "metadata": {},
   "source": [
    "## Neural Architecture Search - Supernet training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f5574",
   "metadata": {},
   "source": [
    "### Create supernet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbc51a",
   "metadata": {},
   "source": [
    "**Before running code in this section, you need to finish supernet implementation.**\n",
    "\n",
    "Please, go to `supernet.py` file and inspect the current implementation of SearchBlock and Supernet classes.\n",
    "Pay attention to the TODOs. You need to implement all of them.\n",
    "\n",
    "Supernet and BasicBlock classes are modified versions of ResNet and BasicBlock classes from `resnet.py`.\n",
    "\n",
    "    Tip: to understand how the Supernet is constructed, compare the implementation of Supernet and ResNet classes. You should probably use diff tool in your IDE or something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213c9dd",
   "metadata": {},
   "source": [
    "Task: briefly describe the differences made to construct supernet."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae6f71f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.371480Z",
     "start_time": "2025-03-12T08:51:25.367695Z"
    }
   },
   "source": [
    "import importlib\n",
    "import speed_up_nn.hw_04.supernet as supernet_lib\n",
    "importlib.reload(supernet_lib)\n",
    "from speed_up_nn.hw_04.supernet import supernet18, BasicBlock"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "30066746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.373657Z",
     "start_time": "2025-03-12T08:51:25.372108Z"
    }
   },
   "source": [
    "# Define inner channel multipliers as in lecture.\n",
    "channel_multipliers = [0.5, 1.0, 2.0]"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "2f11a2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.671946Z",
     "start_time": "2025-03-12T08:51:25.374378Z"
    }
   },
   "source": [
    "supernet = supernet18(num_classes=10, zero_init_residual=True, channel_multipliers=channel_multipliers)\n",
    "supernet.to(device=device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Supernet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "89c42bba",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b72ca7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.674684Z",
     "start_time": "2025-03-12T08:51:25.672704Z"
    }
   },
   "source": [
    "# define hyperparameters for supernet training.\n",
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 50"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "ce8f3ec3",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b2eda34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.678015Z",
     "start_time": "2025-03-12T08:51:25.675421Z"
    }
   },
   "source": [
    "# build optimizer and scheduler for supernet training.\n",
    "optimizer = optim.SGD(supernet.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "03b283fb",
   "metadata": {},
   "source": [
    "### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "id": "04ec0cd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:51:25.682025Z",
     "start_time": "2025-03-12T08:51:25.678655Z"
    }
   },
   "source": [
    "def pretrain_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.sample_random_architecture()\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "ca3c0ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:54:33.058153Z",
     "start_time": "2025-03-12T08:51:25.682637Z"
    }
   },
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = pretrain_one_epoch(supernet, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(supernet, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2498 loss=3.033: 100%|██████████| 24/24 [00:03<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=3.0330, train_accuracy=11.167%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=0, loss=5.782: 100%|██████████| 5/5 [00:00<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=5.7817, test_accuracy=13.980%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=1, lr=0.2490 loss=5.876: 100%|██████████| 24/24 [00:03<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=5.8757, train_accuracy=10.858%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=131.061: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=131.0615, test_accuracy=10.000%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=2, lr=0.2478 loss=4.225: 100%|██████████| 24/24 [00:02<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=4.2247, train_accuracy=10.913%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=2, loss=73.088: 100%|██████████| 5/5 [00:00<00:00,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=73.0884, test_accuracy=10.010%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=3, lr=0.2461 loss=2.840: 100%|██████████| 24/24 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.8402, train_accuracy=10.718%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=3, loss=4.229: 100%|██████████| 5/5 [00:00<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=4.2289, test_accuracy=13.980%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=4, lr=0.2439 loss=2.470: 100%|██████████| 24/24 [00:03<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.4700, train_accuracy=10.699%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=2.490: 100%|██████████| 5/5 [00:00<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.4899, test_accuracy=10.340%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=5, lr=0.2412 loss=2.339: 100%|██████████| 24/24 [00:02<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3386, train_accuracy=10.905%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=2.298: 100%|██████████| 5/5 [00:00<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.2985, test_accuracy=10.270%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=6, lr=0.2381 loss=2.302: 100%|██████████| 24/24 [00:02<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3021, train_accuracy=11.908%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=2.327: 100%|██████████| 5/5 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3272, test_accuracy=12.680%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=7, lr=0.2345 loss=2.282: 100%|██████████| 24/24 [00:03<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.2820, train_accuracy=12.990%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=2.249: 100%|██████████| 5/5 [00:00<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.2489, test_accuracy=14.810%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=8, lr=0.2305 loss=2.230: 100%|██████████| 24/24 [00:02<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.2298, train_accuracy=15.257%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=2.153: 100%|██████████| 5/5 [00:00<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.1531, test_accuracy=17.870%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.2261 loss=2.165: 100%|██████████| 24/24 [00:03<00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.1646, train_accuracy=17.480%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=2.162: 100%|██████████| 5/5 [00:00<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.1618, test_accuracy=18.300%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=10, lr=0.2213 loss=2.099: 100%|██████████| 24/24 [00:02<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.0986, train_accuracy=19.651%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=2.091: 100%|██████████| 5/5 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.0913, test_accuracy=20.730%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=11, lr=0.2161 loss=2.050: 100%|██████████| 24/24 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.0501, train_accuracy=20.854%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=11, loss=2.058: 100%|██████████| 5/5 [00:00<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.0576, test_accuracy=20.930%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=12, lr=0.2106 loss=1.999: 100%|██████████| 24/24 [00:03<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.9989, train_accuracy=22.325%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=12, loss=1.995: 100%|██████████| 5/5 [00:00<00:00,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.9949, test_accuracy=22.290%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.2047 loss=1.952: 100%|██████████| 24/24 [00:03<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.9524, train_accuracy=24.392%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=13, loss=2.071: 100%|██████████| 5/5 [00:00<00:00,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.0713, test_accuracy=21.250%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=14, lr=0.1985 loss=1.921: 100%|██████████| 24/24 [00:03<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.9211, train_accuracy=25.999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=2.041: 100%|██████████| 5/5 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.0406, test_accuracy=22.720%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.1920 loss=1.898: 100%|██████████| 24/24 [00:03<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.8983, train_accuracy=27.094%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=2.026: 100%|██████████| 5/5 [00:00<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.0256, test_accuracy=26.260%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=16, lr=0.1852 loss=1.849: 100%|██████████| 24/24 [00:03<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.8492, train_accuracy=29.268%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=1.905: 100%|██████████| 5/5 [00:00<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.9050, test_accuracy=27.730%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=17, lr=0.1782 loss=1.801: 100%|██████████| 24/24 [00:03<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.8012, train_accuracy=31.250%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=1.890: 100%|██████████| 5/5 [00:00<00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.8899, test_accuracy=28.520%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.1710 loss=1.772: 100%|██████████| 24/24 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.7725, train_accuracy=32.143%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=18, loss=1.783: 100%|██████████| 5/5 [00:00<00:00,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.7826, test_accuracy=33.660%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.1636 loss=1.736: 100%|██████████| 24/24 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.7361, train_accuracy=33.545%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=19, loss=1.692: 100%|██████████| 5/5 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6921, test_accuracy=36.200%\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=20, lr=0.1561 loss=1.725: 100%|██████████| 24/24 [00:02<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.7252, train_accuracy=34.393%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=20, loss=1.717: 100%|██████████| 5/5 [00:00<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.7172, test_accuracy=34.910%\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=21, lr=0.1484 loss=1.704: 100%|██████████| 24/24 [00:02<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.7035, train_accuracy=35.429%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=21, loss=1.685: 100%|██████████| 5/5 [00:00<00:00,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6852, test_accuracy=35.670%\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=22, lr=0.1407 loss=1.702: 100%|██████████| 24/24 [00:03<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.7020, train_accuracy=35.706%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=22, loss=1.755: 100%|██████████| 5/5 [00:00<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.7552, test_accuracy=35.190%\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=23, lr=0.1328 loss=1.659: 100%|██████████| 24/24 [00:03<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.6594, train_accuracy=37.347%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=23, loss=1.644: 100%|██████████| 5/5 [00:00<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6438, test_accuracy=36.940%\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=24, lr=0.1250 loss=1.633: 100%|██████████| 24/24 [00:03<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.6331, train_accuracy=38.395%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=24, loss=1.691: 100%|██████████| 5/5 [00:00<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6910, test_accuracy=36.010%\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=25, lr=0.1172 loss=1.616: 100%|██████████| 24/24 [00:02<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.6159, train_accuracy=38.924%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=25, loss=1.599: 100%|██████████| 5/5 [00:00<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5991, test_accuracy=40.080%\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=26, lr=0.1093 loss=1.595: 100%|██████████| 24/24 [00:02<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5953, train_accuracy=40.194%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=26, loss=1.603: 100%|██████████| 5/5 [00:00<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.6033, test_accuracy=39.750%\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=27, lr=0.1016 loss=1.574: 100%|██████████| 24/24 [00:03<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5743, train_accuracy=40.621%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=27, loss=1.554: 100%|██████████| 5/5 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5539, test_accuracy=41.870%\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=28, lr=0.0939 loss=1.555: 100%|██████████| 24/24 [00:02<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5555, train_accuracy=41.545%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=28, loss=1.598: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5979, test_accuracy=39.280%\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=29, lr=0.0864 loss=1.534: 100%|██████████| 24/24 [00:02<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5339, train_accuracy=42.204%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=29, loss=1.544: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5443, test_accuracy=41.560%\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=30, lr=0.0790 loss=1.520: 100%|██████████| 24/24 [00:03<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.5197, train_accuracy=42.898%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=30, loss=1.551: 100%|██████████| 5/5 [00:00<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5508, test_accuracy=41.970%\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=31, lr=0.0718 loss=1.497: 100%|██████████| 24/24 [00:03<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4974, train_accuracy=43.890%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=31, loss=1.444: 100%|██████████| 5/5 [00:00<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4440, test_accuracy=44.600%\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=32, lr=0.0648 loss=1.483: 100%|██████████| 24/24 [00:03<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4825, train_accuracy=44.554%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=32, loss=1.466: 100%|██████████| 5/5 [00:00<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4656, test_accuracy=46.320%\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=33, lr=0.0580 loss=1.478: 100%|██████████| 24/24 [00:03<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4780, train_accuracy=44.798%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=33, loss=1.497: 100%|██████████| 5/5 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4966, test_accuracy=44.000%\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=34, lr=0.0515 loss=1.464: 100%|██████████| 24/24 [00:02<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4639, train_accuracy=45.408%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=34, loss=1.421: 100%|██████████| 5/5 [00:00<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4209, test_accuracy=46.760%\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=35, lr=0.0453 loss=1.443: 100%|██████████| 24/24 [00:02<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4432, train_accuracy=46.086%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=35, loss=1.599: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5988, test_accuracy=40.230%\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=36, lr=0.0394 loss=1.438: 100%|██████████| 24/24 [00:03<00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4376, train_accuracy=46.474%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=36, loss=1.450: 100%|██████████| 5/5 [00:00<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4501, test_accuracy=45.690%\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=37, lr=0.0339 loss=1.418: 100%|██████████| 24/24 [00:03<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4184, train_accuracy=46.920%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=37, loss=1.436: 100%|██████████| 5/5 [00:00<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4363, test_accuracy=46.860%\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=38, lr=0.0287 loss=1.408: 100%|██████████| 24/24 [00:02<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4079, train_accuracy=47.144%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=38, loss=1.479: 100%|██████████| 5/5 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4788, test_accuracy=43.780%\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=39, lr=0.0239 loss=1.404: 100%|██████████| 24/24 [00:03<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4037, train_accuracy=47.906%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=39, loss=1.344: 100%|██████████| 5/5 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3442, test_accuracy=50.500%\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=40, lr=0.0195 loss=1.396: 100%|██████████| 24/24 [00:03<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3961, train_accuracy=47.788%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=40, loss=1.467: 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4672, test_accuracy=44.220%\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=41, lr=0.0155 loss=1.390: 100%|██████████| 24/24 [00:02<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3900, train_accuracy=48.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=41, loss=1.357: 100%|██████████| 5/5 [00:00<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3573, test_accuracy=49.650%\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=42, lr=0.0119 loss=1.383: 100%|██████████| 24/24 [00:03<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3832, train_accuracy=48.594%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=42, loss=1.347: 100%|██████████| 5/5 [00:00<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3465, test_accuracy=49.600%\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=43, lr=0.0088 loss=1.380: 100%|██████████| 24/24 [00:02<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3798, train_accuracy=48.645%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=43, loss=1.360: 100%|██████████| 5/5 [00:00<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3596, test_accuracy=48.880%\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=44, lr=0.0061 loss=1.375: 100%|██████████| 24/24 [00:03<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3754, train_accuracy=48.865%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=44, loss=1.538: 100%|██████████| 5/5 [00:00<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5377, test_accuracy=42.880%\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=45, lr=0.0039 loss=1.370: 100%|██████████| 24/24 [00:03<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3701, train_accuracy=48.973%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=45, loss=1.373: 100%|██████████| 5/5 [00:00<00:00,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3725, test_accuracy=48.060%\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=46, lr=0.0022 loss=1.372: 100%|██████████| 24/24 [00:03<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3719, train_accuracy=49.044%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=46, loss=1.498: 100%|██████████| 5/5 [00:00<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4982, test_accuracy=44.200%\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=47, lr=0.0010 loss=1.369: 100%|██████████| 24/24 [00:03<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3692, train_accuracy=49.266%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=47, loss=1.439: 100%|██████████| 5/5 [00:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4394, test_accuracy=46.880%\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=48, lr=0.0002 loss=1.368: 100%|██████████| 24/24 [00:03<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3682, train_accuracy=49.076%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=48, loss=1.380: 100%|██████████| 5/5 [00:00<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3802, test_accuracy=48.330%\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=49, lr=0.0000 loss=1.364: 100%|██████████| 24/24 [00:02<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.3638, train_accuracy=49.243%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=49, loss=1.480: 100%|██████████| 5/5 [00:00<00:00,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4803, test_accuracy=44.770%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "63a6b6b5",
   "metadata": {},
   "source": [
    "### Save supernet weights"
   ]
  },
  {
   "cell_type": "code",
   "id": "0a4fdcef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:54:33.298046Z",
     "start_time": "2025-03-12T08:54:33.058992Z"
    }
   },
   "source": [
    "torch.save(supernet.state_dict(), 'supernet.pth')"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "e1b1489c",
   "metadata": {},
   "source": [
    "## Neural Architecture Search - Random Search."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:54:33.302324Z",
     "start_time": "2025-03-12T08:54:33.299021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_accuracy(model: nn.Module, dataloader: DataLoader, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluation\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.shape[0]\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def estimate_latency(model, input_size=(1, 3, 32, 32)):\n",
    "    dummy_input = torch.zeros(*input_size, device=device)\n",
    "    macs, _ = profile(model, inputs=(dummy_input,))\n",
    "    return macs"
   ],
   "id": "410b5409c1693661",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "0b388aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:54:33.306136Z",
     "start_time": "2025-03-12T08:54:33.302976Z"
    }
   },
   "source": [
    "def random_search(\n",
    "        trained_supernet: nn.Module,\n",
    "        val_dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        n_architectures_to_test: int,\n",
    "        target_latency: float,\n",
    "):\n",
    "    history = []\n",
    "    \n",
    "    for _ in tqdm(range(n_architectures_to_test), desc=\"Random Search\"):\n",
    "        trained_supernet.sample_random_architecture()\n",
    "        accuracy = evaluate_accuracy(trained_supernet, val_dataloader, device)\n",
    "        latency = estimate_latency(trained_supernet)\n",
    "        architecture = [block.active_index.item() for block in trained_supernet.search_blocks]\n",
    "\n",
    "        history.append({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"latency\": latency,\n",
    "            \"architecture\": architecture.copy()\n",
    "        })\n",
    "    \n",
    "    # find best\n",
    "    valid_results = [x for x in history if x[\"latency\"] <= target_latency]\n",
    "    if not valid_results:\n",
    "        return 0.0, [], history\n",
    "    \n",
    "    best = max(valid_results, key=lambda x: x[\"accuracy\"])\n",
    "    return best[\"accuracy\"], best[\"architecture\"], history"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "798944f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:55:37.675148Z",
     "start_time": "2025-03-12T08:54:33.306792Z"
    }
   },
   "source": [
    "n_architectures_to_test = 100\n",
    "target_latency = 30 * 1e6 # macs\n",
    "\n",
    "best_acc, best_arch, history = random_search(\n",
    "    trained_supernet=supernet,\n",
    "    val_dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    n_architectures_to_test=n_architectures_to_test,\n",
    "    target_latency=target_latency,\n",
    ")\n",
    "\n",
    "print(f'best architecture: {best_arch} (test_accuracy={best_acc:.3%})')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Search:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.18it/s]\u001B[A\n",
      "Random Search:   1%|          | 1/100 [00:00<01:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.42it/s]\u001B[A\n",
      "Random Search:   2%|▏         | 2/100 [00:01<01:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.72it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.92it/s]\u001B[A\n",
      "Random Search:   3%|▎         | 3/100 [00:01<01:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.74it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.01it/s]\u001B[A\n",
      "Random Search:   4%|▍         | 4/100 [00:02<01:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.53it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  6.97it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 10.14it/s]\u001B[A\n",
      "Random Search:   5%|▌         | 5/100 [00:03<01:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.66it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.82it/s]\u001B[A\n",
      "Random Search:   6%|▌         | 6/100 [00:03<01:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.43it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.28it/s]\u001B[A\n",
      "Random Search:   7%|▋         | 7/100 [00:04<01:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.91it/s]\u001B[A\n",
      "Random Search:   8%|▊         | 8/100 [00:05<00:59,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.67it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.07it/s]\u001B[A\n",
      "Random Search:   9%|▉         | 9/100 [00:05<00:58,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.16it/s]\u001B[A\n",
      "Random Search:  10%|█         | 10/100 [00:06<00:56,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.76it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.32it/s]\u001B[A\n",
      "Random Search:  11%|█         | 11/100 [00:06<00:56,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.08it/s]\u001B[A\n",
      "Random Search:  12%|█▏        | 12/100 [00:07<00:55,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.76it/s]\u001B[A\n",
      "Random Search:  13%|█▎        | 13/100 [00:08<00:54,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.53it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.48it/s]\u001B[A\n",
      "Random Search:  14%|█▍        | 14/100 [00:08<00:54,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.52it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.39it/s]\u001B[A\n",
      "Random Search:  15%|█▌        | 15/100 [00:09<00:54,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.63it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.62it/s]\u001B[A\n",
      "Random Search:  16%|█▌        | 16/100 [00:10<00:53,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.42it/s]\u001B[A\n",
      "Random Search:  17%|█▋        | 17/100 [00:10<00:52,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.36it/s]\u001B[A\n",
      "Random Search:  18%|█▊        | 18/100 [00:11<00:52,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.12it/s]\u001B[A\n",
      "Random Search:  19%|█▉        | 19/100 [00:12<00:51,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.35it/s]\u001B[A\n",
      "Random Search:  20%|██        | 20/100 [00:12<00:50,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.74it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.16it/s]\u001B[A\n",
      "Random Search:  21%|██        | 21/100 [00:13<00:49,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.58it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.88it/s]\u001B[A\n",
      "Random Search:  22%|██▏       | 22/100 [00:13<00:49,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.26it/s]\u001B[A\n",
      "Random Search:  23%|██▎       | 23/100 [00:14<00:48,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.72it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.76it/s]\u001B[A\n",
      "Random Search:  24%|██▍       | 24/100 [00:15<00:47,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.79it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.31it/s]\u001B[A\n",
      "Random Search:  25%|██▌       | 25/100 [00:15<00:46,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.60it/s]\u001B[A\n",
      "Random Search:  26%|██▌       | 26/100 [00:16<00:45,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  40%|████      | 2/5 [00:00<00:00,  4.23it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.48it/s]\u001B[A\n",
      "Random Search:  27%|██▋       | 27/100 [00:17<00:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.02it/s]\u001B[A\n",
      "Random Search:  28%|██▊       | 28/100 [00:17<00:47,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.49it/s]\u001B[A\n",
      "Random Search:  29%|██▉       | 29/100 [00:18<00:46,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.75it/s]\u001B[A\n",
      "Random Search:  30%|███       | 30/100 [00:19<00:45,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.72it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.35it/s]\u001B[A\n",
      "Random Search:  31%|███       | 31/100 [00:19<00:46,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.72it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.96it/s]\u001B[A\n",
      "Random Search:  32%|███▏      | 32/100 [00:20<00:44,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  40%|████      | 2/5 [00:00<00:00,  4.10it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.83it/s]\u001B[A\n",
      "Random Search:  33%|███▎      | 33/100 [00:21<00:45,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:02,  1.92it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  7.71it/s]\u001B[A\n",
      "Random Search:  34%|███▍      | 34/100 [00:21<00:46,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.07it/s]\u001B[A\n",
      "Random Search:  35%|███▌      | 35/100 [00:22<00:44,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.72it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.85it/s]\u001B[A\n",
      "Random Search:  36%|███▌      | 36/100 [00:23<00:42,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.70it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.86it/s]\u001B[A\n",
      "Random Search:  37%|███▋      | 37/100 [00:23<00:43,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.19it/s]\u001B[A\n",
      "Random Search:  38%|███▊      | 38/100 [00:24<00:43,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  40%|████      | 2/5 [00:00<00:00,  4.15it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.68it/s]\u001B[A\n",
      "Random Search:  39%|███▉      | 39/100 [00:25<00:44,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:02,  1.82it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  5.56it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.48it/s]\u001B[A\n",
      "Random Search:  40%|████      | 40/100 [00:26<00:45,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:02,  1.76it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  5.36it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.54it/s]\u001B[A\n",
      "Random Search:  41%|████      | 41/100 [00:27<00:45,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:02,  1.91it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  8.27it/s]\u001B[A\n",
      "Random Search:  42%|████▏     | 42/100 [00:28<00:47,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.54it/s]\u001B[A\n",
      "Random Search:  43%|████▎     | 43/100 [00:28<00:43,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.61it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.62it/s]\u001B[A\n",
      "Random Search:  44%|████▍     | 44/100 [00:29<00:40,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.24it/s]\u001B[A\n",
      "Random Search:  45%|████▌     | 45/100 [00:29<00:37,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.63it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  7.29it/s]\u001B[A\n",
      "Random Search:  46%|████▌     | 46/100 [00:30<00:35,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  9.93it/s]\u001B[A\n",
      "Random Search:  47%|████▋     | 47/100 [00:31<00:34,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.54it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.67it/s]\u001B[A\n",
      "Random Search:  48%|████▊     | 48/100 [00:31<00:34,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.60it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.15it/s]\u001B[A\n",
      "Random Search:  49%|████▉     | 49/100 [00:32<00:33,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.51it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.44it/s]\u001B[A\n",
      "Random Search:  50%|█████     | 50/100 [00:33<00:32,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.84it/s]\u001B[A\n",
      "Random Search:  51%|█████     | 51/100 [00:33<00:31,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.52it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  7.02it/s]\u001B[A\n",
      "Random Search:  52%|█████▏    | 52/100 [00:34<00:30,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.41it/s]\u001B[A\n",
      "Random Search:  53%|█████▎    | 53/100 [00:35<00:30,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.70it/s]\u001B[A\n",
      "Random Search:  54%|█████▍    | 54/100 [00:35<00:29,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.70it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.82it/s]\u001B[A\n",
      "Random Search:  55%|█████▌    | 55/100 [00:36<00:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.76it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.18it/s]\u001B[A\n",
      "Random Search:  56%|█████▌    | 56/100 [00:36<00:27,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.11it/s]\u001B[A\n",
      "Random Search:  57%|█████▋    | 57/100 [00:37<00:26,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.70it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00,  9.88it/s]\u001B[A\n",
      "Random Search:  58%|█████▊    | 58/100 [00:38<00:26,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.36it/s]\u001B[A\n",
      "Random Search:  59%|█████▉    | 59/100 [00:38<00:25,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.65it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.80it/s]\u001B[A\n",
      "Random Search:  60%|██████    | 60/100 [00:39<00:24,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 10.08it/s]\u001B[A\n",
      "Random Search:  61%|██████    | 61/100 [00:39<00:24,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.64it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.82it/s]\u001B[A\n",
      "Random Search:  62%|██████▏   | 62/100 [00:40<00:23,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.74it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.12it/s]\u001B[A\n",
      "Random Search:  63%|██████▎   | 63/100 [00:41<00:22,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.47it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.16it/s]\u001B[A\n",
      "Random Search:  64%|██████▍   | 64/100 [00:41<00:22,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.55it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.37it/s]\u001B[A\n",
      "Random Search:  65%|██████▌   | 65/100 [00:42<00:22,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.44it/s]\u001B[A\n",
      "Evaluation:  60%|██████    | 3/5 [00:00<00:00,  6.95it/s]\u001B[A\n",
      "Random Search:  66%|██████▌   | 66/100 [00:43<00:21,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.48it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  8.95it/s]\u001B[A\n",
      "Random Search:  67%|██████▋   | 67/100 [00:43<00:20,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.68it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.02it/s]\u001B[A\n",
      "Random Search:  68%|██████▊   | 68/100 [00:44<00:20,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.44it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  8.99it/s]\u001B[A\n",
      "Random Search:  69%|██████▉   | 69/100 [00:45<00:19,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.21it/s]\u001B[A\n",
      "Random Search:  70%|███████   | 70/100 [00:45<00:19,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.57it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.30it/s]\u001B[A\n",
      "Random Search:  71%|███████   | 71/100 [00:46<00:18,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.59it/s]\u001B[A\n",
      "Random Search:  72%|███████▏  | 72/100 [00:46<00:17,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.67it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.04it/s]\u001B[A\n",
      "Random Search:  73%|███████▎  | 73/100 [00:47<00:17,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.92it/s]\u001B[A\n",
      "Random Search:  74%|███████▍  | 74/100 [00:48<00:16,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.54it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.64it/s]\u001B[A\n",
      "Random Search:  75%|███████▌  | 75/100 [00:48<00:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.98it/s]\u001B[A\n",
      "Random Search:  76%|███████▌  | 76/100 [00:49<00:15,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.76it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.95it/s]\u001B[A\n",
      "Random Search:  77%|███████▋  | 77/100 [00:50<00:14,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.66it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.78it/s]\u001B[A\n",
      "Random Search:  78%|███████▊  | 78/100 [00:50<00:13,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.78it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 10.07it/s]\u001B[A\n",
      "Random Search:  79%|███████▉  | 79/100 [00:51<00:13,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.63it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.60it/s]\u001B[A\n",
      "Random Search:  80%|████████  | 80/100 [00:51<00:12,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.69it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.04it/s]\u001B[A\n",
      "Random Search:  81%|████████  | 81/100 [00:52<00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.67it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.72it/s]\u001B[A\n",
      "Random Search:  82%|████████▏ | 82/100 [00:53<00:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.78it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.43it/s]\u001B[A\n",
      "Random Search:  83%|████████▎ | 83/100 [00:53<00:10,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.36it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.09it/s]\u001B[A\n",
      "Random Search:  84%|████████▍ | 84/100 [00:54<00:10,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.14it/s]\u001B[A\n",
      "Random Search:  85%|████████▌ | 85/100 [00:55<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.73it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.98it/s]\u001B[A\n",
      "Random Search:  86%|████████▌ | 86/100 [00:55<00:08,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.68it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.36it/s]\u001B[A\n",
      "Random Search:  87%|████████▋ | 87/100 [00:56<00:08,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.51it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.25it/s]\u001B[A\n",
      "Random Search:  88%|████████▊ | 88/100 [00:56<00:07,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.63it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.03it/s]\u001B[A\n",
      "Random Search:  89%|████████▉ | 89/100 [00:57<00:06,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.76it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.37it/s]\u001B[A\n",
      "Random Search:  90%|█████████ | 90/100 [00:58<00:06,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.81it/s]\u001B[A\n",
      "Evaluation: 100%|██████████| 5/5 [00:00<00:00, 10.04it/s]\u001B[A\n",
      "Random Search:  91%|█████████ | 91/100 [00:58<00:05,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.94it/s]\u001B[A\n",
      "Random Search:  92%|█████████▏| 92/100 [00:59<00:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.81it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.57it/s]\u001B[A\n",
      "Random Search:  93%|█████████▎| 93/100 [01:00<00:04,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.77it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.28it/s]\u001B[A\n",
      "Random Search:  94%|█████████▍| 94/100 [01:00<00:03,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.02it/s]\u001B[A\n",
      "Random Search:  95%|█████████▌| 95/100 [01:01<00:03,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.71it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.48it/s]\u001B[A\n",
      "Random Search:  96%|█████████▌| 96/100 [01:01<00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.74it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.74it/s]\u001B[A\n",
      "Random Search:  97%|█████████▋| 97/100 [01:02<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.75it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.93it/s]\u001B[A\n",
      "Random Search:  98%|█████████▊| 98/100 [01:03<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.73it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00, 10.19it/s]\u001B[A\n",
      "Random Search:  99%|█████████▉| 99/100 [01:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluation:  20%|██        | 1/5 [00:00<00:01,  2.61it/s]\u001B[A\n",
      "Evaluation:  80%|████████  | 4/5 [00:00<00:00,  9.16it/s]\u001B[A\n",
      "Random Search: 100%|██████████| 100/100 [01:04<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "best architecture: [0, 0, 0, 1, 0, 0, 0, 2] (test_accuracy=47.540%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "48b2a50e",
   "metadata": {},
   "source": [
    "## Train found architecture from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45eb2d",
   "metadata": {},
   "source": [
    "Go to `Create your baseline model` section.\n",
    "\n",
    "Change model definition to this to build unitialized best architecture from the search space:\n",
    "\n",
    "```python\n",
    "model = supernet18(num_classes=10, zero_init_residual=True, channel_multipliers=channel_multipliers)\n",
    "model.to(device=device)\n",
    "model.sample(best_architecture)\n",
    "```\n",
    "\n",
    "After this, simply run all the cells in that section."
   ]
  },
  {
   "cell_type": "code",
   "id": "3d15fa78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:55:37.978550Z",
     "start_time": "2025-03-12T08:55:37.676025Z"
    }
   },
   "source": [
    "best_model = supernet18(num_classes=10, zero_init_residual=True,channel_multipliers=channel_multipliers)\n",
    "best_model.to(device=device)\n",
    "best_model.sample(best_arch)\n",
    "print(best_arch)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 2]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:55:37.983533Z",
     "start_time": "2025-03-12T08:55:37.979493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch_best(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ],
   "id": "2001e954983d4918",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:58:18.534656Z",
     "start_time": "2025-03-12T08:55:37.985532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 100\n",
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "optimizer = optim.SGD(supernet.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch_best(best_model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(best_model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ],
   "id": "5ff4ee80c90a6624",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2499 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3759, train_accuracy=10.026%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=0, loss=2.337: 100%|██████████| 5/5 [00:00<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3369, test_accuracy=10.440%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=1, lr=0.2498 loss=2.378: 100%|██████████| 24/24 [00:02<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3776, train_accuracy=9.880%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=2.361: 100%|██████████| 5/5 [00:00<00:00,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3610, test_accuracy=10.600%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=2, lr=0.2494 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3756, train_accuracy=9.906%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=2, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.670%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=3, lr=0.2490 loss=2.377: 100%|██████████| 24/24 [00:02<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3771, train_accuracy=9.831%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=3, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3648, test_accuracy=10.640%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=4, lr=0.2485 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3756, train_accuracy=10.225%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.660%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=5, lr=0.2478 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3757, train_accuracy=9.902%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.630%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=6, lr=0.2470 loss=2.373: 100%|██████████| 24/24 [00:02<00:00,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3734, train_accuracy=10.128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3646, test_accuracy=10.650%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=7, lr=0.2461 loss=2.374: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3744, train_accuracy=10.020%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.680%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=8, lr=0.2450 loss=2.377: 100%|██████████| 24/24 [00:03<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3767, train_accuracy=10.004%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.670%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.2439 loss=2.378: 100%|██████████| 24/24 [00:02<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3778, train_accuracy=9.800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.610%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=10, lr=0.2426 loss=2.379: 100%|██████████| 24/24 [00:02<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3787, train_accuracy=9.920%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.570%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=11, lr=0.2412 loss=2.375: 100%|██████████| 24/24 [00:02<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3748, train_accuracy=10.030%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=11, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.640%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=12, lr=0.2397 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3757, train_accuracy=9.910%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=12, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3646, test_accuracy=10.700%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.2381 loss=2.376: 100%|██████████| 24/24 [00:03<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3761, train_accuracy=10.030%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=13, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.680%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=14, lr=0.2364 loss=2.375: 100%|██████████| 24/24 [00:03<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3751, train_accuracy=10.146%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.700%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.2345 loss=2.375: 100%|██████████| 24/24 [00:03<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3751, train_accuracy=10.162%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.710%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=16, lr=0.2326 loss=2.375: 100%|██████████| 24/24 [00:03<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3754, train_accuracy=10.111%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.720%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=17, lr=0.2305 loss=2.375: 100%|██████████| 24/24 [00:02<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3753, train_accuracy=10.071%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.700%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.2284 loss=2.374: 100%|██████████| 24/24 [00:02<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3739, train_accuracy=10.229%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=18, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.730%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.2261 loss=2.375: 100%|██████████| 24/24 [00:02<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3753, train_accuracy=10.042%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=19, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.650%\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=20, lr=0.2238 loss=2.377: 100%|██████████| 24/24 [00:02<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3768, train_accuracy=10.026%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=20, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.640%\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=21, lr=0.2213 loss=2.378: 100%|██████████| 24/24 [00:02<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3776, train_accuracy=10.162%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=21, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3653, test_accuracy=10.680%\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=22, lr=0.2188 loss=2.374: 100%|██████████| 24/24 [00:02<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3736, train_accuracy=10.099%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=22, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.690%\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=23, lr=0.2161 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3760, train_accuracy=10.071%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=23, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.670%\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=24, lr=0.2134 loss=2.378: 100%|██████████| 24/24 [00:02<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3776, train_accuracy=10.057%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=24, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.590%\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=25, lr=0.2106 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3758, train_accuracy=10.124%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=25, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.600%\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=26, lr=0.2077 loss=2.375: 100%|██████████| 24/24 [00:03<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3748, train_accuracy=10.059%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=26, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.690%\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=27, lr=0.2047 loss=2.376: 100%|██████████| 24/24 [00:03<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3760, train_accuracy=9.983%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=27, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.720%\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=28, lr=0.2016 loss=2.378: 100%|██████████| 24/24 [00:03<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3776, train_accuracy=9.701%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=28, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.710%\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=29, lr=0.1985 loss=2.374: 100%|██████████| 24/24 [00:02<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3739, train_accuracy=10.079%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=29, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.680%\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=30, lr=0.1953 loss=2.377: 100%|██████████| 24/24 [00:02<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3772, train_accuracy=9.971%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=30, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3654, test_accuracy=10.660%\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=31, lr=0.1920 loss=2.376: 100%|██████████| 24/24 [00:03<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3762, train_accuracy=9.983%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=31, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.690%\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=32, lr=0.1886 loss=2.379: 100%|██████████| 24/24 [00:03<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3789, train_accuracy=9.782%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=32, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.700%\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=33, lr=0.1852 loss=2.374: 100%|██████████| 24/24 [00:03<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3741, train_accuracy=10.276%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=33, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.600%\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=34, lr=0.1817 loss=2.378: 100%|██████████| 24/24 [00:02<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3776, train_accuracy=9.847%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=34, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.610%\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=35, lr=0.1782 loss=2.377: 100%|██████████| 24/24 [00:02<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3772, train_accuracy=9.934%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=35, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.700%\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=36, lr=0.1746 loss=2.376: 100%|██████████| 24/24 [00:03<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3763, train_accuracy=9.926%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=36, loss=2.366: 100%|██████████| 5/5 [00:00<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3656, test_accuracy=10.640%\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=37, lr=0.1710 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3764, train_accuracy=9.912%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=37, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.610%\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=38, lr=0.1673 loss=2.375: 100%|██████████| 24/24 [00:02<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3749, train_accuracy=10.034%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=38, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3653, test_accuracy=10.690%\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=39, lr=0.1636 loss=2.376: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3763, train_accuracy=9.682%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=39, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3651, test_accuracy=10.690%\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=40, lr=0.1599 loss=2.375: 100%|██████████| 24/24 [00:03<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3747, train_accuracy=10.252%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=40, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3650, test_accuracy=10.710%\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=41, lr=0.1561 loss=2.374: 100%|██████████| 24/24 [00:02<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3740, train_accuracy=10.091%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=41, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3652, test_accuracy=10.710%\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=42, lr=0.1523 loss=2.375: 100%|██████████| 24/24 [00:02<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3749, train_accuracy=10.061%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=42, loss=2.365: 100%|██████████| 5/5 [00:00<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3649, test_accuracy=10.680%\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=43, lr=0.1491 loss=2.376:  83%|████████▎ | 20/24 [00:02<00:00,  7.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     loss, accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch_best\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, train_accuracy=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     12\u001B[0m     loss, accuracy \u001B[38;5;241m=\u001B[39m validate_one_epoch(best_model, criterion, test_dataloader, device, epoch)\n",
      "Cell \u001B[0;32mIn[56], line 17\u001B[0m, in \u001B[0;36mtrain_one_epoch_best\u001B[0;34m(model, criterion, dataloader, optimizer, scheduler, device, epoch)\u001B[0m\n\u001B[1;32m     14\u001B[0m total_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     16\u001B[0m wrapped_dataloader \u001B[38;5;241m=\u001B[39m tqdm(\u001B[38;5;28menumerate\u001B[39m(dataloader), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataloader))\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m wrapped_dataloader:\n\u001B[1;32m     18\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m     19\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1327\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1327\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1293\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1289\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1290\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1293\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1294\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1295\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1119\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1120\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1128\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1131\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1133\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/multiprocessing/queues.py:107\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    106\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
