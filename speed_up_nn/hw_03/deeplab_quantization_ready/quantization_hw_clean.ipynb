{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14864c63-1ec1-456d-a026-786f650f4f16",
   "metadata": {},
   "source": [
    "### Квантует DeepLabV3 MobilenetV3\n",
    "\n",
    "Стартуем с трейнлупа, который нам выдали pytorch\n",
    "\n",
    "Датасет COCO, https://cocodataset.org/#download \n",
    "Качаем train2017 и val2017\n",
    "\n",
    "Можно использовать [сабсет](https://drive.google.com/file/d/1qdtAbK-iOsgJZxjbBva0pw2Vi5penjPc/view?usp=sharing) трейна на 20000, но тогда заранее залезте в класс датасета, и добавте работу с пропущенными картинками\n",
    "\n",
    "Баллы: 20 баллов Static Quantization + 20 баллов Quantization Aware Training + 10 баллов Distillation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:48:33.575903Z",
     "start_time": "2025-03-02T09:48:27.006224Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install pycocotools",
   "id": "953d46691481e587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools)\r\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: numpy in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from pycocotools) (1.24.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (4.43.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (6.1.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools) (3.20.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hflabs/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\r\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.2/9.2 MB\u001B[0m \u001B[31m49.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: matplotlib, pycocotools\r\n",
      "Successfully installed matplotlib-3.7.5 pycocotools-2.0.7\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "29bf7a00-f092-413e-9789-7fe81046d248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:34:57.332501Z",
     "start_time": "2025-03-04T20:34:55.977009Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # Разрешаем TensorFloat-32\n",
    "torch.set_float32_matmul_precision('medium')  # Оптимизация для современных GPU\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.ao.quantization.quantize_fx import convert_fx\n",
    "from torch.ao.quantization.quantize_fx import fuse_fx\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.quantization_utils.fake_quantization import fake_quantization\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.quantization_utils.static_quantization import quantize_static\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.train import evaluate\n",
    "from train import get_dataset\n",
    "from train import train_one_epoch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "cf831e0a-003e-40fb-9b3f-ad1a225751c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:34:57.720889Z",
     "start_time": "2025-03-04T20:34:57.718512Z"
    }
   },
   "source": [
    "# Вытащил дефолтные аргументы, чтобы не упражняться с argparse в ноутбуке\n",
    "with Path('./torch_default_args.pickle').open('rb') as file:\n",
    "    args = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2acb1e03-f5fc-4ec4-a089-54f464c17b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:34:58.465638Z",
     "start_time": "2025-03-04T20:34:58.463412Z"
    }
   },
   "source": [
    "# Подобирайте под ваше железо\n",
    "args.data_path = '/data/coco/'\n",
    "args.epochs = 1\n",
    "args.batch_size = 16\n",
    "args.workers = 16"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4d5b93ea-21fc-4e72-8bab-e16d8722fb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:34:59.567655Z",
     "start_time": "2025-03-04T20:34:59.562627Z"
    }
   },
   "source": [
    "args"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(amp=False, aux_loss=False, backend='pil', batch_size=16, data_path='/data/coco/', dataset='coco', device='cuda', dist_url='env://', epochs=1, lr=0.01, lr_warmup_decay=0.01, lr_warmup_epochs=0, lr_warmup_method='linear', model='deeplabv3_mobilenet_v3_large', momentum=0.9, output_dir='.', print_freq=10, resume='', start_epoch=0, test_only=False, use_deterministic_algorithms=False, use_v2=False, weight_decay=0.0001, weights=None, weights_backbone=None, workers=16, world_size=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "97d07a33-dd10-41d5-84f2-6c3c6cc22971",
   "metadata": {},
   "source": [
    "### Сначала просто валидация обычной сетки, прям на гпу"
   ]
  },
  {
   "cell_type": "code",
   "id": "73ddaa10-5909-451b-ae90-6ee0f013da09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:35:01.234114Z",
     "start_time": "2025-03-04T20:35:00.834269Z"
    }
   },
   "source": [
    "model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1)\n",
    "model.eval();"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "0b15585f-78f7-4437-8f14-aea099b82f3f",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T20:35:01.876205Z",
     "start_time": "2025-03-04T20:35:01.362531Z"
    }
   },
   "source": [
    "if args.output_dir:\n",
    "    utils.mkdir(args.output_dir)\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "dataset_test, num_classes = get_dataset(args, is_train=False)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=16, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:35:03.074055Z",
     "start_time": "2025-03-04T20:35:03.071051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, SequentialSampler\n",
    "import numpy as np\n",
    "\n",
    "def get_subset(dataset, ratio=0.5, batch_size=1, num_workers=16):\n",
    "    dataset_size = len(dataset)\n",
    "    subset_size = int(dataset_size * ratio)\n",
    "    indices = list(map(int, np.random.permutation(dataset_size)[:subset_size]))\n",
    "    subset = Subset(dataset, indices)\n",
    "    sampler = SequentialSampler(subset)\n",
    "    subset_loader = DataLoader(\n",
    "        subset, batch_size=batch_size, sampler=sampler, \n",
    "        num_workers=num_workers, collate_fn=utils.collate_fn\n",
    "    )\n",
    "\n",
    "    return subset_loader\n"
   ],
   "id": "124a6f0cc96daebc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T20:35:04.650466Z",
     "start_time": "2025-03-04T20:35:04.533015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model.cuda()"
   ],
   "id": "4b956bc7c415160e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ec3c78a1-6a74-48ec-938c-d511918645f1",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:33:26.497843Z",
     "start_time": "2025-03-04T08:33:21.348945Z"
    }
   },
   "source": [
    "subset = get_subset(dataset_test, ratio=0.2, batch_size=16)\n",
    "confmat = evaluate(model, subset, device=device, num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m subset \u001B[38;5;241m=\u001B[39m get_subset(dataset_test, ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m confmat \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(confmat)\n",
      "File \u001B[0;32m~/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/train.py:84\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, data_loader, device, num_classes)\u001B[0m\n\u001B[1;32m     81\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     83\u001B[0m image, target \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mto(device), target\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 84\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m output \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     87\u001B[0m confmat\u001B[38;5;241m.\u001B[39mupdate(target\u001B[38;5;241m.\u001B[39mflatten(), output\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mflatten())\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torchvision/models/segmentation/_utils.py:23\u001B[0m, in \u001B[0;36m_SimpleSegmentationModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     21\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:]\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# contract: features is a dict of tensors\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m result \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m     26\u001B[0m x \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torchvision/models/_utils.py:69\u001B[0m, in \u001B[0;36mIntermediateLayerGetter.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     67\u001B[0m out \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 69\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_layers:\n\u001B[1;32m     71\u001B[0m         out_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_layers[name]\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torchvision/models/resnet.py:150\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    147\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(out)\n\u001B[1;32m    148\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m--> 150\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(out)\n\u001B[1;32m    152\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/conv.py:458\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/torch/nn/modules/conv.py:454\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    452\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    453\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "4465c3c9-0eb8-46d4-ae0d-79336cd1b7c9",
   "metadata": {},
   "source": [
    "### Заквантуем статические сетку, посмотрим на точность и скорость"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ebfca70-948a-4e42-b7c9-2a9984108f83",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:40:19.134561Z",
     "start_time": "2025-03-03T17:39:17.256893Z"
    }
   },
   "source": [
    "# Квантуем\n",
    "# Делаем fuse, делаем quantize_static и quantize_utils (посмотрите что там с кодом)\n",
    "# Можно покрутить параметр num_batches, чтобы посмотреть сколько нужно данных на калибровку\n",
    "# fused_model = fuse_fx(model) # KeyError: 'backbone.layer1.0.conv1.1'\n",
    "q_model = quantize_static(\n",
    "    model=model,\n",
    "    data_loader=get_subset(dataset_test, ratio=0.1, batch_size=16),\n",
    "    num_batches=16,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "81e8eda0-19fc-4a50-8a7a-9aa9f7f79391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:11:24.649237Z",
     "start_time": "2025-03-02T19:11:24.647761Z"
    }
   },
   "source": [
    "# Замерим скорость квантованной модели на CPU\n",
    "# Не забываем, от размера батча будет зависить буст"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae59f5e2-9fa3-4d39-ba25-13817a65a755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:48:36.857704Z",
     "start_time": "2025-03-03T17:40:19.135521Z"
    }
   },
   "source": [
    "# Замеряем с бачтом 1, буста нет (3 batch/s)\n",
    "subset_1batch = get_subset(dataset_test, ratio=0.1, batch_size=1)\n",
    "confmat_1_batch = evaluate(q_model, subset_1batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_1_batch)\n",
    "\n",
    "# Замеряем с батчом 32, буст есть\n",
    "subset_16batch = get_subset(dataset_test, ratio=0.1, batch_size=16)\n",
    "confmat_16_batch = evaluate(q_model, subset_16batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_16_batch)\n",
    "# Мораль, latency != throughput. В сетке всегда есть накладные расходы, кроме перемалывания матричек"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [  0/500]  eta: 0:08:04  batch_time: 0.4801 (0.4801)  time: 0.9691  data: 0.4888  max mem: 12013\n",
      "Test:  [ 10/500]  eta: 0:03:05  batch_time: 0.3357 (0.3315)  time: 0.3778  data: 0.0452  max mem: 12013\n",
      "Test:  [ 20/500]  eta: 0:02:51  batch_time: 0.3212 (0.3326)  time: 0.3274  data: 0.0010  max mem: 12013\n",
      "Test:  [ 30/500]  eta: 0:02:42  batch_time: 0.3045 (0.3282)  time: 0.3283  data: 0.0007  max mem: 12013\n",
      "Test:  [ 40/500]  eta: 0:02:36  batch_time: 0.3125 (0.3259)  time: 0.3206  data: 0.0005  max mem: 12013\n",
      "Test:  [ 50/500]  eta: 0:02:35  batch_time: 0.3284 (0.3344)  time: 0.3462  data: 0.0009  max mem: 12013\n",
      "Test:  [ 60/500]  eta: 0:02:29  batch_time: 0.3284 (0.3306)  time: 0.3425  data: 0.0009  max mem: 12013\n",
      "Test:  [ 70/500]  eta: 0:02:26  batch_time: 0.3377 (0.3317)  time: 0.3267  data: 0.0009  max mem: 12013\n",
      "Test:  [ 80/500]  eta: 0:02:22  batch_time: 0.3426 (0.3307)  time: 0.3329  data: 0.0009  max mem: 12013\n",
      "Test:  [ 90/500]  eta: 0:02:17  batch_time: 0.3275 (0.3288)  time: 0.3206  data: 0.0009  max mem: 12013\n",
      "Test:  [100/500]  eta: 0:02:14  batch_time: 0.3208 (0.3295)  time: 0.3266  data: 0.0009  max mem: 12013\n",
      "Test:  [110/500]  eta: 0:02:10  batch_time: 0.3036 (0.3277)  time: 0.3246  data: 0.0009  max mem: 12013\n",
      "Test:  [120/500]  eta: 0:02:06  batch_time: 0.3088 (0.3273)  time: 0.3184  data: 0.0009  max mem: 12013\n",
      "Test:  [130/500]  eta: 0:02:03  batch_time: 0.3363 (0.3273)  time: 0.3273  data: 0.0009  max mem: 12013\n",
      "Test:  [140/500]  eta: 0:02:00  batch_time: 0.3356 (0.3288)  time: 0.3401  data: 0.0009  max mem: 12013\n",
      "Test:  [150/500]  eta: 0:01:56  batch_time: 0.3063 (0.3280)  time: 0.3345  data: 0.0009  max mem: 12013\n",
      "Test:  [160/500]  eta: 0:01:52  batch_time: 0.3028 (0.3260)  time: 0.3088  data: 0.0009  max mem: 12013\n",
      "Test:  [170/500]  eta: 0:01:49  batch_time: 0.3048 (0.3258)  time: 0.3115  data: 0.0009  max mem: 12013\n",
      "Test:  [180/500]  eta: 0:01:45  batch_time: 0.3086 (0.3255)  time: 0.3231  data: 0.0009  max mem: 12013\n",
      "Test:  [190/500]  eta: 0:01:42  batch_time: 0.3086 (0.3248)  time: 0.3186  data: 0.0009  max mem: 12013\n",
      "Test:  [200/500]  eta: 0:01:38  batch_time: 0.3057 (0.3251)  time: 0.3239  data: 0.0009  max mem: 12013\n",
      "Test:  [210/500]  eta: 0:01:35  batch_time: 0.3057 (0.3249)  time: 0.3277  data: 0.0009  max mem: 12013\n",
      "Test:  [220/500]  eta: 0:01:32  batch_time: 0.3054 (0.3243)  time: 0.3187  data: 0.0009  max mem: 12013\n",
      "Test:  [230/500]  eta: 0:01:28  batch_time: 0.2994 (0.3242)  time: 0.3192  data: 0.0009  max mem: 12013\n",
      "Test:  [240/500]  eta: 0:01:25  batch_time: 0.3182 (0.3252)  time: 0.3367  data: 0.0009  max mem: 12013\n",
      "Test:  [250/500]  eta: 0:01:22  batch_time: 0.3420 (0.3257)  time: 0.3456  data: 0.0009  max mem: 12013\n",
      "Test:  [260/500]  eta: 0:01:19  batch_time: 0.3360 (0.3261)  time: 0.3391  data: 0.0009  max mem: 12013\n",
      "Test:  [270/500]  eta: 0:01:15  batch_time: 0.3321 (0.3265)  time: 0.3385  data: 0.0009  max mem: 12013\n",
      "Test:  [280/500]  eta: 0:01:12  batch_time: 0.3408 (0.3266)  time: 0.3361  data: 0.0009  max mem: 12013\n",
      "Test:  [290/500]  eta: 0:01:09  batch_time: 0.3393 (0.3267)  time: 0.3313  data: 0.0009  max mem: 12013\n",
      "Test:  [300/500]  eta: 0:01:06  batch_time: 0.3393 (0.3273)  time: 0.3383  data: 0.0009  max mem: 12013\n",
      "Test:  [310/500]  eta: 0:01:02  batch_time: 0.3383 (0.3272)  time: 0.3363  data: 0.0009  max mem: 12013\n",
      "Test:  [320/500]  eta: 0:00:59  batch_time: 0.3221 (0.3274)  time: 0.3324  data: 0.0009  max mem: 12013\n",
      "Test:  [330/500]  eta: 0:00:56  batch_time: 0.3113 (0.3271)  time: 0.3288  data: 0.0009  max mem: 12013\n",
      "Test:  [340/500]  eta: 0:00:52  batch_time: 0.3098 (0.3275)  time: 0.3298  data: 0.0009  max mem: 12013\n",
      "Test:  [350/500]  eta: 0:00:49  batch_time: 0.3197 (0.3271)  time: 0.3278  data: 0.0009  max mem: 12013\n",
      "Test:  [360/500]  eta: 0:00:46  batch_time: 0.3033 (0.3265)  time: 0.3124  data: 0.0009  max mem: 12013\n",
      "Test:  [370/500]  eta: 0:00:42  batch_time: 0.3033 (0.3267)  time: 0.3218  data: 0.0009  max mem: 12013\n",
      "Test:  [380/500]  eta: 0:00:39  batch_time: 0.3353 (0.3270)  time: 0.3380  data: 0.0009  max mem: 12013\n",
      "Test:  [390/500]  eta: 0:00:36  batch_time: 0.3151 (0.3267)  time: 0.3294  data: 0.0009  max mem: 12013\n",
      "Test:  [400/500]  eta: 0:00:33  batch_time: 0.3357 (0.3267)  time: 0.3226  data: 0.0009  max mem: 12013\n",
      "Test:  [410/500]  eta: 0:00:29  batch_time: 0.3191 (0.3267)  time: 0.3291  data: 0.0009  max mem: 12013\n",
      "Test:  [420/500]  eta: 0:00:26  batch_time: 0.3080 (0.3275)  time: 0.3466  data: 0.0009  max mem: 12013\n",
      "Test:  [430/500]  eta: 0:00:23  batch_time: 0.3377 (0.3275)  time: 0.3458  data: 0.0009  max mem: 12013\n",
      "Test:  [440/500]  eta: 0:00:19  batch_time: 0.3183 (0.3282)  time: 0.3450  data: 0.0009  max mem: 12013\n",
      "Test:  [450/500]  eta: 0:00:16  batch_time: 0.3343 (0.3282)  time: 0.3457  data: 0.0009  max mem: 12013\n",
      "Test:  [460/500]  eta: 0:00:13  batch_time: 0.3232 (0.3280)  time: 0.3263  data: 0.0009  max mem: 12013\n",
      "Test:  [470/500]  eta: 0:00:09  batch_time: 0.3375 (0.3282)  time: 0.3302  data: 0.0009  max mem: 12013\n",
      "Test:  [480/500]  eta: 0:00:06  batch_time: 0.3355 (0.3277)  time: 0.3217  data: 0.0009  max mem: 12013\n",
      "Test:  [490/500]  eta: 0:00:03  batch_time: 0.3341 (0.3280)  time: 0.3258  data: 0.0009  max mem: 12013\n",
      "Test: Total time: 0:02:45\n",
      "Latency: 0.3281 sec/batch\n",
      "Throughput: 3.02 samples/sec\n",
      "global correct: 91.4\n",
      "average row correct: ['93.0', '78.5', '84.9', '64.3', '56.5', '61.8', '81.2', '86.4', '95.4', '62.1', '58.1', '77.9', '92.3', '80.5', '87.9', '91.4', '63.3', '92.2', '68.5', '82.8', '68.7']\n",
      "IoU: ['90.1', '75.7', '63.7', '46.0', '51.4', '55.2', '76.3', '74.1', '82.9', '48.0', '55.8', '35.2', '74.7', '73.5', '79.7', '82.6', '31.2', '78.1', '47.1', '78.3', '63.2']\n",
      "mean IoU: 64.9\n",
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/utils.py:295: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 0/32]  eta: 0:09:49  batch_time: 14.9917 (14.9917)  time: 18.4106  data: 3.4188  max mem: 12013\n",
      "Test:  [10/32]  eta: 0:04:23  batch_time: 10.6069 (11.6406)  time: 11.9851  data: 0.3113  max mem: 12013\n",
      "Test:  [20/32]  eta: 0:02:11  batch_time: 10.1415 (10.7310)  time: 10.5540  data: 0.0007  max mem: 12013\n",
      "Test:  [30/32]  eta: 0:00:21  batch_time: 9.4150 (10.5005)  time: 9.9081  data: 0.0006  max mem: 12013\n",
      "Test: Total time: 0:05:32\n",
      "Latency: 10.2317 sec/batch\n",
      "Throughput: 1.51 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.6', '92.3', '86.4', '84.7', '15.3', '76.8', '87.5', '70.2', '82.7', '38.2', '87.1', '56.5', '69.6', '90.1', '85.3', '90.2', '64.4', '88.2', '71.2', '66.4', '60.8']\n",
      "IoU: ['92.6', '83.7', '68.2', '75.2', '14.9', '60.7', '81.4', '53.2', '70.0', '31.0', '79.0', '37.6', '49.5', '80.2', '77.7', '81.9', '46.4', '78.9', '56.9', '62.6', '53.8']\n",
      "mean IoU: 63.6\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "087a60bf-6fb1-4b14-b44e-d06efb9c9f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T18:08:52.752886Z",
     "start_time": "2025-03-03T17:49:55.878830Z"
    }
   },
   "source": [
    "# Замерим скорость оригинальной модели на CPU\n",
    "confmat_original_batch = evaluate(model.cpu(), subset_16batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_original_batch)\n",
    "# У меня на intel i9 при батчсайзе 32 получился x2 буст"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/32]  eta: 0:27:39  batch_time: 48.6258 (48.6258)  time: 51.8678  data: 3.2419  max mem: 12013\n",
      "Test:  [10/32]  eta: 0:14:55  batch_time: 36.4321 (40.3779)  time: 40.7074  data: 0.2954  max mem: 12013\n",
      "Test:  [20/32]  eta: 0:07:28  batch_time: 34.8171 (37.1569)  time: 36.6203  data: 0.0007  max mem: 12013\n",
      "Test:  [30/32]  eta: 0:01:12  batch_time: 32.4484 (36.3104)  time: 34.1087  data: 0.0006  max mem: 12013\n",
      "Test: Total time: 0:18:56\n",
      "Latency: 35.3861 sec/batch\n",
      "Throughput: 0.44 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.3', '92.9', '86.6', '85.0', '15.5', '77.6', '88.0', '71.0', '82.0', '39.9', '86.5', '59.5', '70.5', '90.2', '86.7', '90.6', '67.0', '88.5', '71.6', '66.2', '61.1']\n",
      "IoU: ['92.6', '82.8', '68.0', '75.9', '15.1', '60.1', '81.2', '53.3', '69.8', '31.7', '79.1', '38.4', '49.9', '79.7', '78.3', '82.0', '48.2', '78.5', '55.7', '61.5', '54.0']\n",
      "mean IoU: 63.6\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "b3e66e00-55a3-4ddf-b376-07e402ff9bbe",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T18:19:21.575140Z",
     "start_time": "2025-03-03T18:08:52.754064Z"
    }
   },
   "source": [
    "# Посчитаем метрики квантованной модели\n",
    "# У меня была просадка где-то до 65 IoU\n",
    "q_model.cpu()\n",
    "confmat = evaluate(q_model, subset, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/63]  eta: 0:14:31  batch_time: 10.5986 (10.5986)  time: 13.8304  data: 3.2316  max mem: 12013\n",
      "Test:  [10/63]  eta: 0:09:07  batch_time: 10.2706 (10.0009)  time: 10.3261  data: 0.2941  max mem: 12013\n",
      "Test:  [20/63]  eta: 0:08:08  batch_time: 10.2907 (11.1660)  time: 11.2325  data: 0.0008  max mem: 12013\n",
      "Test:  [30/63]  eta: 0:05:56  batch_time: 9.5196 (10.6614)  time: 11.0645  data: 0.0007  max mem: 12013\n",
      "Test:  [40/63]  eta: 0:03:59  batch_time: 8.9075 (10.3123)  time: 9.4501  data: 0.0005  max mem: 12013\n",
      "Test:  [50/63]  eta: 0:02:13  batch_time: 9.0070 (10.1584)  time: 9.4104  data: 0.0009  max mem: 12013\n",
      "Test:  [60/63]  eta: 0:00:30  batch_time: 8.6819 (9.9656)  time: 9.2860  data: 0.0009  max mem: 12013\n",
      "Test: Total time: 0:10:28\n",
      "Latency: 9.8939 sec/batch\n",
      "Throughput: 1.59 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.6', '87.6', '79.1', '57.6', '51.2', '58.3', '78.5', '63.7', '90.6', '33.9', '88.5', '53.0', '83.1', '87.3', '84.9', '89.8', '48.4', '81.3', '51.9', '95.1', '70.0']\n",
      "IoU: ['92.3', '67.1', '68.9', '46.6', '43.9', '50.4', '73.9', '54.2', '78.4', '27.9', '75.1', '38.4', '69.5', '79.0', '78.2', '81.5', '29.3', '68.4', '44.5', '91.0', '65.8']\n",
      "mean IoU: 63.1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ef8e149e-08b7-4f90-b3a7-e312adb6ece8",
   "metadata": {},
   "source": [
    "### Делаем Quantization Aware Training. Используем готовый трейнплуп от pytorch"
   ]
  },
  {
   "cell_type": "code",
   "id": "de375f28-bf82-4c3a-924d-03c3a75376e9",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:03:55.218889Z",
     "start_time": "2025-03-05T07:32:25.676970Z"
    }
   },
   "source": [
    "# Делаем фейк квантование, идём смотреть quantization_utils\n",
    "import importlib\n",
    "import speed_up_nn.hw_03.deeplab_quantization_ready.train as train\n",
    "importlib.reload(train)\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.train import evaluate, criterion\n",
    "subset = get_subset(dataset_test, ratio=0.1, batch_size=16)\n",
    "qat_model = fake_quantization(\n",
    "    model=model,\n",
    "    data_loader=subset\n",
    ")\n",
    "confmat = evaluate(qat_model.cpu(), subset, device='cpu', num_classes=num_classes) # too long\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/32]  eta: 0:28:34  batch_time: 50.3174 (50.3174)  time: 53.5771  data: 3.2594  max mem: 14166\n",
      "Test:  [10/32]  eta: 0:23:21  batch_time: 53.9812 (63.3683)  time: 63.7009  data: 0.2972  max mem: 14166\n",
      "Test:  [20/32]  eta: 0:12:48  batch_time: 54.3311 (63.8353)  time: 64.5547  data: 0.0010  max mem: 14166\n",
      "Test:  [30/32]  eta: 0:02:01  batch_time: 54.6831 (60.3745)  time: 58.7689  data: 0.0006  max mem: 14166\n",
      "Test: Total time: 0:31:23\n",
      "Latency: 58.7198 sec/batch\n",
      "Throughput: 0.27 samples/sec\n",
      "global correct: 92.8\n",
      "average row correct: ['97.1', '85.4', '68.5', '92.2', '33.6', '52.7', '82.0', '47.6', '95.1', '43.3', '88.8', '30.3', '81.8', '91.3', '94.0', '89.3', '50.6', '56.3', '70.4', '86.4', '87.2']\n",
      "IoU: ['91.8', '78.4', '63.0', '82.7', '29.1', '45.9', '71.4', '44.8', '89.7', '33.9', '84.5', '24.4', '63.0', '83.1', '79.2', '82.2', '27.6', '54.7', '63.2', '79.5', '74.4']\n",
      "mean IoU: 64.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/utils.py:295: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(val)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "49e6d85d-82cc-4d99-81de-3d12a9e6e375",
   "metadata": {},
   "source": [
    "### Тут берём из train.py скрипт main() и вытаскиваем трейн луп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d671589-a9e9-4459-a59a-b4cea6f653b5",
   "metadata": {},
   "source": [
    "1. Не забыть провалидировать модель fake quant до qat\n",
    "2. Не забыть провалидировать модель после обучения\n",
    "3. Конвертировать модель из fake quant в обычный quant\n",
    "4. Проверить точность и скорость модели\n",
    "Должно хватить пары эпох, lr надо будет покрутить.\n",
    "Цель минимум это поднять точность конвертированной QAT модели (будет у вас QAT до обучения 55, станет 56, молодцы!)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8d8b72c-76c2-4480-a1b1-8f7ee33e5c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:03:41.891716Z",
     "start_time": "2025-03-04T20:35:13.815161Z"
    }
   },
   "source": [
    "# Подсказка, учить надо в train и на GPU\n",
    "torch.cuda.empty_cache()\n",
    "qat_model.cuda();\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "device = 'cuda'\n",
    "print_freq = 10\n",
    "subset_train = get_subset(dataset_test, ratio=0.1, batch_size=2)\n",
    "\n",
    "# Создаём оптимизатор, LR-схедулер и AMP scaler\n",
    "optimizer = torch.optim.Adam(qat_model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "# Запускаем QAT обучение\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(\n",
    "        model=qat_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=subset_train,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        device=device,\n",
    "        epoch=epoch,\n",
    "        print_freq=print_freq,\n",
    "        scaler=None # todo: check RuntimeError: expected scalar type Float but found Half\n",
    "    )\n",
    "qat_model.eval()\n",
    "confmat = evaluate(qat_model.cpu(), subset, device='cpu', num_classes=num_classes) # too long\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37093/2363223584.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/train.py:121: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=scaler is not None):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/250]  eta: 0:08:19  lr: 0.001  loss: 2.0419 (2.0419)  time: 1.9962  data: 0.5975  max mem: 7201\n",
      "Epoch: [0]  [ 10/250]  eta: 0:04:38  lr: 0.001  loss: 2.0419 (2.3889)  time: 1.1589  data: 0.0570  max mem: 14166\n",
      "Epoch: [0]  [ 20/250]  eta: 0:04:26  lr: 0.001  loss: 0.9557 (2.0632)  time: 1.1157  data: 0.0034  max mem: 14166\n",
      "evaluating...\n",
      "Test:  [ 0/32]  eta: 0:28:29  batch_time: 50.7214 (50.7214)  time: 53.4176  data: 2.6960  max mem: 14166\n",
      "Test:  [10/32]  eta: 0:18:59  batch_time: 51.3892 (51.5184)  time: 51.7949  data: 0.2460  max mem: 14166\n",
      "Test:  [20/32]  eta: 0:10:29  batch_time: 54.5449 (52.2773)  time: 52.3902  data: 0.0011  max mem: 14166\n",
      "Test:  [30/32]  eta: 0:01:47  batch_time: 54.8708 (53.6436)  time: 54.8486  data: 0.0007  max mem: 14166\n",
      "Test: Total time: 0:27:58\n",
      "Latency: 52.3425 sec/batch\n",
      "Throughput: 0.30 samples/sec\n",
      "global correct: 73.4\n",
      "average row correct: ['89.3', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '17.6', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "IoU: ['74.6', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '7.8', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "mean IoU: 3.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/utils.py:295: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(val)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "bfa71d29-c5bf-47fd-9d62-593345f76cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:08:56.857318Z",
     "start_time": "2025-03-04T21:03:41.892857Z"
    }
   },
   "source": [
    "# Инференс делаем на cpu, предварительно конвертируя модельку на CPU\n",
    "qat_model.cpu()\n",
    "int_qat_model = convert_fx(qat_model)\n",
    "confmat = evaluate(int_qat_model.cpu(), subset, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/32]  eta: 0:07:15  batch_time: 10.5175 (10.5175)  time: 13.5967  data: 3.0791  max mem: 14166\n",
      "Test:  [10/32]  eta: 0:03:39  batch_time: 10.1766 (9.6517)  time: 9.9616  data: 0.2807  max mem: 14166\n",
      "Test:  [20/32]  eta: 0:01:58  batch_time: 10.1177 (9.7282)  time: 9.7220  data: 0.0009  max mem: 14166\n",
      "Test:  [30/32]  eta: 0:00:20  batch_time: 10.1177 (9.9203)  time: 10.1023  data: 0.0005  max mem: 14166\n",
      "Test: Total time: 0:05:13\n",
      "Latency: 9.6759 sec/batch\n",
      "Throughput: 1.59 samples/sec\n",
      "global correct: 72.8\n",
      "average row correct: ['88.4', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '19.1', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "IoU: ['74.1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '8.1', '0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "mean IoU: 3.9\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "f83e30de-5a6a-45a2-bf7e-27b6ac3c9d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T09:20:12.445404Z",
     "start_time": "2025-03-05T09:20:10.425222Z"
    }
   },
   "source": [
    "# Точность модели fake quant и квантованной после конвертации будут разные\n",
    "# Так и должно быть, всё таки мы эмулировали квантование.\n",
    "dummy_input = torch.randn(1, 3, 520, 520)\n",
    "scripted_model = torch.jit.trace(int_qat_model, dummy_input, strict=False)\n",
    "scripted_model.save(\"int_qat_model.pt\")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "1c3213cc-9a38-44dd-a35e-f4f0f79db8bb",
   "metadata": {},
   "source": [
    "### Балуемся с дистилляцией\n",
    "Врываемся в train.py и добавляем туда дистилляцию, просто по последнему слою (до софтмакса, на логитах) делаем стягивание по MSE\n",
    "\n",
    "Цель поднять точность и ускорить сходимость.\n",
    "\n",
    "Балуемся с весами обычного и distill лосса.\n",
    "\n",
    "Можно вообще выкинуть classification loss и смоделировать ситуацию когда вам не выдали лейблов (жиза)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T09:14:49.361411Z",
     "start_time": "2025-03-05T09:14:49.263732Z"
    }
   },
   "cell_type": "code",
   "source": "int_qat_model",
   "id": "b645cf9f14eb2033",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (backbone): Module(\n",
       "    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.031454846262931824, zero_point=0, padding=(3, 3))\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.013712501153349876, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.01829022914171219, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.027659667655825615, zero_point=58)\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.04986891150474548, zero_point=72)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.013912894763052464, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.023724617436528206, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.02566472440958023, zero_point=63)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.01221059076488018, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.026861317455768585, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.035033706575632095, zero_point=68)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.01845330372452736, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.012704610824584961, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.03674319386482239, zero_point=56)\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.031645212322473526, zero_point=58)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.008187312632799149, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.012618383392691612, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.032962288707494736, zero_point=66)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.010478830896317959, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.009127989411354065, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.022160230204463005, zero_point=64)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.012276641093194485, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.011988113634288311, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.026722967624664307, zero_point=63)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.016940690577030182, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.013101470656692982, zero_point=0, padding=(1, 1))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.036710482090711594, zero_point=63)\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.027277976274490356, zero_point=65)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.018250565975904465, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.016062496230006218, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.03903035447001457, zero_point=74)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.015085669234395027, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.017223244532942772, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.03333673253655434, zero_point=72)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.01661784201860428, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.015930263325572014, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.031049128621816635, zero_point=67)\n",
       "      )\n",
       "      (4): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.01577617973089218, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.017381727695465088, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.03551638126373291, zero_point=66)\n",
       "      )\n",
       "      (5): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.018939968198537827, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.03286631405353546, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.05447225645184517, zero_point=57)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Module(\n",
       "      (0): Module(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.01836732029914856, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.022010765969753265, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.061783235520124435, zero_point=60)\n",
       "        (downsample): Module(\n",
       "          (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.08385398238897324, zero_point=48)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.0185911376029253, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.023959284648299217, zero_point=0, padding=(4, 4), dilation=(4, 4))\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.07678955048322678, zero_point=56)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.02264581061899662, zero_point=0)\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.026512546464800835, zero_point=0, padding=(4, 4), dilation=(4, 4))\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.13676713407039642, zero_point=59)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Module(\n",
       "    (0): Module(\n",
       "      (convs): Module(\n",
       "        (0): Module(\n",
       "          (0): QuantizedConvReLU2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.12193340808153152, zero_point=0)\n",
       "        )\n",
       "        (1): Module(\n",
       "          (0): QuantizedConvReLU2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12193340808153152, zero_point=0, padding=(12, 12), dilation=(12, 12))\n",
       "        )\n",
       "        (2): Module(\n",
       "          (0): QuantizedConvReLU2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12193340808153152, zero_point=0, padding=(24, 24), dilation=(24, 24))\n",
       "        )\n",
       "        (3): Module(\n",
       "          (0): QuantizedConvReLU2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12193340808153152, zero_point=0, padding=(36, 36), dilation=(36, 36))\n",
       "        )\n",
       "        (4): Module(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): QuantizedConvReLU2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.05601539462804794, zero_point=0)\n",
       "        )\n",
       "      )\n",
       "      (project): Module(\n",
       "        (0): QuantizedConvReLU2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.06234443187713623, zero_point=0)\n",
       "        (3): QuantizedDropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05684414133429527, zero_point=0, padding=(1, 1))\n",
       "    (4): QuantizedConv2d(256, 21, kernel_size=(1, 1), stride=(1, 1), scale=0.5338781476020813, zero_point=41)\n",
       "  )\n",
       "  (aux_classifier): Module(\n",
       "    (0): QuantizedConvReLU2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05850644037127495, zero_point=0, padding=(1, 1))\n",
       "    (3): QuantizedDropout(p=0.1, inplace=False)\n",
       "    (4): QuantizedConv2d(256, 21, kernel_size=(1, 1), stride=(1, 1), scale=0.32249802350997925, zero_point=49)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T10:22:17.447398Z",
     "start_time": "2025-03-05T10:22:17.445670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import speed_up_nn.hw_03.deeplab_quantization_ready.train as train\n",
    "importlib.reload(train)\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.train import train_one_epoch_distill\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch_distill(\n",
    "        teacher_model=model.cuda(),\n",
    "        student_model=int_qat_model.cuda(),\n",
    "        optimizer=optimizer,\n",
    "        data_loader=subset,\n",
    "        device=device,\n",
    "        epoch=epoch,\n",
    "        print_freq=print_freq,\n",
    "        scaler=scaler\n",
    "    )\n"
   ],
   "id": "f5a11d02bfe94721",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "confmat = evaluate(int_qat_model.cpu(), subset, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "id": "da5ff60a0bdfd59d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
