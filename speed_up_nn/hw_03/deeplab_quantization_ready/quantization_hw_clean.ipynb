{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14864c63-1ec1-456d-a026-786f650f4f16",
   "metadata": {},
   "source": [
    "### Квантует DeepLabV3 MobilenetV3\n",
    "\n",
    "Стартуем с трейнлупа, который нам выдали pytorch\n",
    "\n",
    "Датасет COCO, https://cocodataset.org/#download \n",
    "Качаем train2017 и val2017\n",
    "\n",
    "Можно использовать [сабсет](https://drive.google.com/file/d/1qdtAbK-iOsgJZxjbBva0pw2Vi5penjPc/view?usp=sharing) трейна на 20000, но тогда заранее залезте в класс датасета, и добавте работу с пропущенными картинками\n",
    "\n",
    "Баллы: 20 баллов Static Quantization + 20 баллов Quantization Aware Training + 10 баллов Distillation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:48:33.575903Z",
     "start_time": "2025-03-02T09:48:27.006224Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install pycocotools",
   "id": "953d46691481e587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools)\r\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: numpy in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from pycocotools) (1.24.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (4.43.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (6.1.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools) (3.20.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hflabs/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\r\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.2/9.2 MB\u001B[0m \u001B[31m49.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: matplotlib, pycocotools\r\n",
      "Successfully installed matplotlib-3.7.5 pycocotools-2.0.7\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "29bf7a00-f092-413e-9789-7fe81046d248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:39.443030Z",
     "start_time": "2025-03-02T19:19:38.111710Z"
    }
   },
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.ao.quantization.quantize_fx import convert_fx\n",
    "from torch.ao.quantization.quantize_fx import fuse_fx\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from quantization_utils.fake_quantization import fake_quantization\n",
    "from quantization_utils.static_quantization import quantize_static\n",
    "from train import evaluate\n",
    "from train import get_dataset\n",
    "from train import train_one_epoch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "cf831e0a-003e-40fb-9b3f-ad1a225751c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:41.103699Z",
     "start_time": "2025-03-02T19:19:41.100705Z"
    }
   },
   "source": [
    "# Вытащил дефолтные аргументы, чтобы не упражняться с argparse в ноутбуке\n",
    "with Path('./torch_default_args.pickle').open('rb') as file:\n",
    "    args = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2acb1e03-f5fc-4ec4-a089-54f464c17b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:41.881114Z",
     "start_time": "2025-03-02T19:19:41.877716Z"
    }
   },
   "source": [
    "# Подобирайте под ваше железо\n",
    "args.data_path = '/data/coco/'\n",
    "args.epochs = 1\n",
    "args.batch_size = 16\n",
    "args.workers = 16"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4d5b93ea-21fc-4e72-8bab-e16d8722fb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:45.894929Z",
     "start_time": "2025-03-02T19:19:45.888589Z"
    }
   },
   "source": [
    "args"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(amp=False, aux_loss=False, backend='pil', batch_size=16, data_path='/data/coco/', dataset='coco', device='cuda', dist_url='env://', epochs=1, lr=0.01, lr_warmup_decay=0.01, lr_warmup_epochs=0, lr_warmup_method='linear', model='deeplabv3_mobilenet_v3_large', momentum=0.9, output_dir='.', print_freq=10, resume='', start_epoch=0, test_only=False, use_deterministic_algorithms=False, use_v2=False, weight_decay=0.0001, weights=None, weights_backbone=None, workers=16, world_size=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "97d07a33-dd10-41d5-84f2-6c3c6cc22971",
   "metadata": {},
   "source": [
    "### Сначала просто валидация обычной сетки, прям на гпу"
   ]
  },
  {
   "cell_type": "code",
   "id": "73ddaa10-5909-451b-ae90-6ee0f013da09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:47.717457Z",
     "start_time": "2025-03-02T19:19:47.304459Z"
    }
   },
   "source": [
    "model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1)\n",
    "model.eval();"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "0b15585f-78f7-4437-8f14-aea099b82f3f",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T19:19:49.921848Z",
     "start_time": "2025-03-02T19:19:49.402529Z"
    }
   },
   "source": [
    "if args.output_dir:\n",
    "    utils.mkdir(args.output_dir)\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "dataset_test, num_classes = get_dataset(args, is_train=False)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=16, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ec3c78a1-6a74-48ec-938c-d511918645f1",
   "metadata": {
    "scrolled": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-02T19:19:53.861816Z"
    }
   },
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model.cuda()\n",
    "confmat = evaluate(model, data_loader_test, device=device, num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [  0/313]  eta: 0:33:29    time: 6.4195  data: 2.9631  max mem: 6087\n",
      "Test:  [ 10/313]  eta: 0:11:26    time: 2.2645  data: 0.2985  max mem: 6550\n",
      "Test:  [ 20/313]  eta: 0:10:04    time: 1.8443  data: 0.0317  max mem: 6746\n",
      "Test:  [ 30/313]  eta: 0:10:15    time: 2.1259  data: 0.0345  max mem: 9602\n",
      "Test:  [ 40/313]  eta: 0:09:48    time: 2.2516  data: 0.0361  max mem: 10826\n",
      "Test:  [ 50/313]  eta: 0:09:17    time: 2.0346  data: 0.0329  max mem: 10826\n",
      "Test:  [ 60/313]  eta: 0:08:52    time: 2.0021  data: 0.0326  max mem: 10826\n",
      "Test:  [ 70/313]  eta: 0:08:28    time: 2.0223  data: 0.0335  max mem: 10826\n",
      "Test:  [ 80/313]  eta: 0:08:07    time: 2.0563  data: 0.0344  max mem: 10826\n",
      "Test:  [ 90/313]  eta: 0:07:41    time: 1.9829  data: 0.0346  max mem: 10826\n",
      "Test:  [100/313]  eta: 0:07:15    time: 1.8560  data: 0.0322  max mem: 10826\n",
      "Test:  [110/313]  eta: 0:06:56    time: 1.9832  data: 0.0342  max mem: 10826\n",
      "Test:  [120/313]  eta: 0:06:38    time: 2.1665  data: 0.0368  max mem: 12239\n",
      "Test:  [130/313]  eta: 0:06:15    time: 2.0392  data: 0.0338  max mem: 12239\n",
      "Test:  [140/313]  eta: 0:05:52    time: 1.8830  data: 0.0314  max mem: 12239\n",
      "Test:  [150/313]  eta: 0:05:29    time: 1.8266  data: 0.0310  max mem: 12239\n",
      "Test:  [160/313]  eta: 0:05:08    time: 1.8682  data: 0.0317  max mem: 12239\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4465c3c9-0eb8-46d4-ae0d-79336cd1b7c9",
   "metadata": {},
   "source": [
    "### Заквантуем статические сетку, посмотрим на точность и скорость"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ebfca70-948a-4e42-b7c9-2a9984108f83",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T18:47:51.307732Z",
     "start_time": "2025-03-02T18:46:51.848695Z"
    }
   },
   "source": [
    "# Квантуем\n",
    "# Делаем fuse, делаем quantize_static и quantize_utils (посмотрите что там с кодом)\n",
    "# Можно покрутить параметр num_batches, чтобы посмотреть сколько нужно данных на калибровку\n",
    "q_model = quantize_static(\n",
    "    model=model,\n",
    "    data_loader=data_loader_test,\n",
    "    num_batches=16,\n",
    ")\n",
    "fused_model = fuse_fx(q_model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "81e8eda0-19fc-4a50-8a7a-9aa9f7f79391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:11:24.649237Z",
     "start_time": "2025-03-02T19:11:24.647761Z"
    }
   },
   "source": [
    "# Замерим скорость квантованной модели на CPU\n",
    "# Не забываем, от размера батча будет зависить буст"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae59f5e2-9fa3-4d39-ba25-13817a65a755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:11:24.649780Z",
     "start_time": "2025-03-02T19:11:24.648337Z"
    }
   },
   "source": [
    "# Замеряем с бачтом 1, буста нет (3 batch/s)\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")\n",
    "confmat_1_batch = evaluate(fused_model, data_loader_test, device='cpu', num_classes=num_classes)\n",
    "print(confmat_1_batch)\n",
    "# Замеряем с батчом 32, буст есть (\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=16, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")\n",
    "confmat_32_batch = evaluate(fused_model, data_loader_test, device='cpu', num_classes=num_classes)\n",
    "print(confmat_32_batch)\n",
    "# Мораль, latency != throughput. В сетке всегда есть накладные расходы, кроме перемалывания матричек"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "087a60bf-6fb1-4b14-b44e-d06efb9c9f23",
   "metadata": {},
   "source": [
    "# Замерим скорость оригинальной модели на CPU\n",
    "confmat_original_batch = evaluate(model, data_loader_test, device='cpu', num_classes=num_classes)\n",
    "print(confmat_original_batch)\n",
    "# У меня на intel i9 при батчсайзе 32 получился x2 буст"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3e66e00-55a3-4ddf-b376-07e402ff9bbe",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Посчитаем метрики квантованной модели\n",
    "# У меня была просадка где-то до 65 IoU\n",
    "q_model.cpu()\n",
    "confmat = evaluate(q_model, data_loader_test, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef8e149e-08b7-4f90-b3a7-e312adb6ece8",
   "metadata": {},
   "source": [
    "### Делаем Quantization Aware Training. Используем готовый трейнплуп от pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de375f28-bf82-4c3a-924d-03c3a75376e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Делаем фейк квантование, идём смотреть quantization_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6d85d-82cc-4d99-81de-3d12a9e6e375",
   "metadata": {},
   "source": [
    "### Тут берём из train.py скрипт main() и вытаскиваем трейн луп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d671589-a9e9-4459-a59a-b4cea6f653b5",
   "metadata": {},
   "source": [
    "1. Не забыть провалидировать модель fake quant до qat\n",
    "2. Не забыть провалидировать модель после обучения\n",
    "3. Конвертировать модель из fake quant в обычный quant\n",
    "4. Проверить точность и скорость модели\n",
    "Должно хватить пары эпох, lr надо будет покрутить.\n",
    "Цель минимум это поднять точность конвертированной QAT модели (будет у вас QAT до обучения 55, станет 56, молодцы!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8b72c-76c2-4480-a1b1-8f7ee33e5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсказка, учить надо в train и на GPU\n",
    "qat_model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa71d29-c5bf-47fd-9d62-593345f76cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инференс делаем на cpu, предварительно конвертируя модельку на CPU\n",
    "qat_model.cpu()\n",
    "int_qat_model = convert_fx(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e30de-5a6a-45a2-bf7e-27b6ac3c9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность модели fake quant и квантованной после конвертации будут разные\n",
    "# Так и должно быть, всё таки мы эмулировали квантование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3213cc-9a38-44dd-a35e-f4f0f79db8bb",
   "metadata": {},
   "source": [
    "### Балуемся с дистилляцией\n",
    "Врываемся в train.py и добавляем туда дистилляцию, просто по последнему слою (до софтмакса, на логитах) делаем стягивание по MSE\n",
    "\n",
    "Цель поднять точность и ускорить сходимость.\n",
    "\n",
    "Балуемся с весами обычного и distill лосса.\n",
    "\n",
    "Можно вообще выкинуть classification loss и смоделировать ситуацию когда вам не выдали лейблов (жиза)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f1a2f-76c2-48d5-ac99-040460da12a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
