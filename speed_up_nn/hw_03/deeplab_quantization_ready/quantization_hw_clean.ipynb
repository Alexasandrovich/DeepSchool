{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14864c63-1ec1-456d-a026-786f650f4f16",
   "metadata": {},
   "source": [
    "### Квантует DeepLabV3 MobilenetV3\n",
    "\n",
    "Стартуем с трейнлупа, который нам выдали pytorch\n",
    "\n",
    "Датасет COCO, https://cocodataset.org/#download \n",
    "Качаем train2017 и val2017\n",
    "\n",
    "Можно использовать [сабсет](https://drive.google.com/file/d/1qdtAbK-iOsgJZxjbBva0pw2Vi5penjPc/view?usp=sharing) трейна на 20000, но тогда заранее залезте в класс датасета, и добавте работу с пропущенными картинками\n",
    "\n",
    "Баллы: 20 баллов Static Quantization + 20 баллов Quantization Aware Training + 10 баллов Distillation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:48:33.575903Z",
     "start_time": "2025-03-02T09:48:27.006224Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install pycocotools",
   "id": "953d46691481e587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools)\r\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: numpy in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from pycocotools) (1.24.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (4.43.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hflabs/.local/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools) (6.1.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools) (3.20.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hflabs/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n",
      "Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\r\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.2/9.2 MB\u001B[0m \u001B[31m49.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: matplotlib, pycocotools\r\n",
      "Successfully installed matplotlib-3.7.5 pycocotools-2.0.7\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "29bf7a00-f092-413e-9789-7fe81046d248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:36:57.994300Z",
     "start_time": "2025-03-03T17:36:56.266676Z"
    }
   },
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.ao.quantization.quantize_fx import convert_fx\n",
    "from torch.ao.quantization.quantize_fx import fuse_fx\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from quantization_utils.fake_quantization import fake_quantization\n",
    "from quantization_utils.static_quantization import quantize_static\n",
    "from speed_up_nn.hw_03.deeplab_quantization_ready.train import evaluate\n",
    "from train import get_dataset\n",
    "from train import train_one_epoch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "cf831e0a-003e-40fb-9b3f-ad1a225751c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:36:58.743859Z",
     "start_time": "2025-03-03T17:36:58.741123Z"
    }
   },
   "source": [
    "# Вытащил дефолтные аргументы, чтобы не упражняться с argparse в ноутбуке\n",
    "with Path('./torch_default_args.pickle').open('rb') as file:\n",
    "    args = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2acb1e03-f5fc-4ec4-a089-54f464c17b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:36:59.801408Z",
     "start_time": "2025-03-03T17:36:59.797735Z"
    }
   },
   "source": [
    "# Подобирайте под ваше железо\n",
    "args.data_path = '/data/coco/'\n",
    "args.epochs = 1\n",
    "args.batch_size = 16\n",
    "args.workers = 16"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4d5b93ea-21fc-4e72-8bab-e16d8722fb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T08:28:48.832391Z",
     "start_time": "2025-03-03T08:28:48.825348Z"
    }
   },
   "source": [
    "args"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(amp=False, aux_loss=False, backend='pil', batch_size=16, data_path='/data/coco/', dataset='coco', device='cuda', dist_url='env://', epochs=1, lr=0.01, lr_warmup_decay=0.01, lr_warmup_epochs=0, lr_warmup_method='linear', model='deeplabv3_mobilenet_v3_large', momentum=0.9, output_dir='.', print_freq=10, resume='', start_epoch=0, test_only=False, use_deterministic_algorithms=False, use_v2=False, weight_decay=0.0001, weights=None, weights_backbone=None, workers=16, world_size=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "97d07a33-dd10-41d5-84f2-6c3c6cc22971",
   "metadata": {},
   "source": [
    "### Сначала просто валидация обычной сетки, прям на гпу"
   ]
  },
  {
   "cell_type": "code",
   "id": "73ddaa10-5909-451b-ae90-6ee0f013da09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:37:02.171769Z",
     "start_time": "2025-03-03T17:37:01.719832Z"
    }
   },
   "source": [
    "model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1)\n",
    "model.eval();"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "0b15585f-78f7-4437-8f14-aea099b82f3f",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:37:02.911721Z",
     "start_time": "2025-03-03T17:37:02.398810Z"
    }
   },
   "source": [
    "if args.output_dir:\n",
    "    utils.mkdir(args.output_dir)\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "dataset_test, num_classes = get_dataset(args, is_train=False)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=16, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:37:04.781411Z",
     "start_time": "2025-03-03T17:37:04.777167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, SequentialSampler\n",
    "import numpy as np\n",
    "\n",
    "def get_subset(dataset, ratio=0.5, batch_size=1, num_workers=16):\n",
    "    dataset_size = len(dataset)\n",
    "    subset_size = int(dataset_size * ratio)\n",
    "    indices = list(map(int, np.random.permutation(dataset_size)[:subset_size]))\n",
    "    subset = Subset(dataset, indices)\n",
    "    sampler = SequentialSampler(subset)\n",
    "    subset_loader = DataLoader(\n",
    "        subset, batch_size=batch_size, sampler=sampler, \n",
    "        num_workers=num_workers, collate_fn=utils.collate_fn\n",
    "    )\n",
    "\n",
    "    return subset_loader\n"
   ],
   "id": "124a6f0cc96daebc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ec3c78a1-6a74-48ec-938c-d511918645f1",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:39:17.255709Z",
     "start_time": "2025-03-03T17:37:06.182221Z"
    }
   },
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model.cuda()\n",
    "subset = get_subset(dataset_test, ratio=0.2, batch_size=16)\n",
    "confmat = evaluate(model, subset, device=device, num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/63]  eta: 0:06:25  batch_time: 3.7221 (3.7221)  time: 6.1194  data: 2.3972  max mem: 4874\n",
      "Test:  [10/63]  eta: 0:02:09  batch_time: 2.0445 (2.1954)  time: 2.4421  data: 0.2467  max mem: 6720\n",
      "Test:  [20/63]  eta: 0:01:46  batch_time: 2.0445 (2.3287)  time: 2.2948  data: 0.0357  max mem: 12013\n",
      "Test:  [30/63]  eta: 0:01:16  batch_time: 1.8603 (2.1922)  time: 2.2272  data: 0.0367  max mem: 12013\n",
      "Test:  [40/63]  eta: 0:00:50  batch_time: 1.7907 (2.1050)  time: 1.9014  data: 0.0313  max mem: 12013\n",
      "Test:  [50/63]  eta: 0:00:27  batch_time: 1.7936 (2.0650)  time: 1.8979  data: 0.0300  max mem: 12013\n",
      "Test:  [60/63]  eta: 0:00:06  batch_time: 1.7632 (2.0241)  time: 1.8878  data: 0.0294  max mem: 12013\n",
      "Test: Total time: 0:02:10\n",
      "Latency: 2.0073 sec/batch\n",
      "Throughput: 7.64 samples/sec\n",
      "global correct: 93.2\n",
      "average row correct: ['96.4', '88.4', '80.2', '58.1', '52.1', '60.2', '78.9', '65.7', '90.1', '35.1', '88.7', '55.6', '84.4', '87.3', '86.2', '90.2', '50.5', '81.9', '52.6', '95.2', '70.6']\n",
      "IoU: ['92.3', '67.0', '69.4', '46.3', '44.2', '50.6', '74.1', '55.2', '78.3', '28.4', '74.9', '38.9', '69.9', '78.7', '78.9', '81.6', '30.3', '68.9', '45.0', '91.1', '65.1']\n",
      "mean IoU: 63.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/utils.py:295: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(val)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "4465c3c9-0eb8-46d4-ae0d-79336cd1b7c9",
   "metadata": {},
   "source": [
    "### Заквантуем статические сетку, посмотрим на точность и скорость"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ebfca70-948a-4e42-b7c9-2a9984108f83",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:40:19.134561Z",
     "start_time": "2025-03-03T17:39:17.256893Z"
    }
   },
   "source": [
    "# Квантуем\n",
    "# Делаем fuse, делаем quantize_static и quantize_utils (посмотрите что там с кодом)\n",
    "# Можно покрутить параметр num_batches, чтобы посмотреть сколько нужно данных на калибровку\n",
    "# fused_model = fuse_fx(model) # KeyError: 'backbone.layer1.0.conv1.1'\n",
    "q_model = quantize_static(\n",
    "    model=model,\n",
    "    data_loader=get_subset(dataset_test, ratio=0.1, batch_size=16),\n",
    "    num_batches=16,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/anaconda3/envs/ds/lib/python3.8/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "81e8eda0-19fc-4a50-8a7a-9aa9f7f79391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:11:24.649237Z",
     "start_time": "2025-03-02T19:11:24.647761Z"
    }
   },
   "source": [
    "# Замерим скорость квантованной модели на CPU\n",
    "# Не забываем, от размера батча будет зависить буст"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae59f5e2-9fa3-4d39-ba25-13817a65a755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:48:36.857704Z",
     "start_time": "2025-03-03T17:40:19.135521Z"
    }
   },
   "source": [
    "# Замеряем с бачтом 1, буста нет (3 batch/s)\n",
    "subset_1batch = get_subset(dataset_test, ratio=0.1, batch_size=1)\n",
    "confmat_1_batch = evaluate(q_model, subset_1batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_1_batch)\n",
    "\n",
    "# Замеряем с батчом 32, буст есть\n",
    "subset_16batch = get_subset(dataset_test, ratio=0.1, batch_size=16)\n",
    "confmat_16_batch = evaluate(q_model, subset_16batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_16_batch)\n",
    "# Мораль, latency != throughput. В сетке всегда есть накладные расходы, кроме перемалывания матричек"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [  0/500]  eta: 0:08:04  batch_time: 0.4801 (0.4801)  time: 0.9691  data: 0.4888  max mem: 12013\n",
      "Test:  [ 10/500]  eta: 0:03:05  batch_time: 0.3357 (0.3315)  time: 0.3778  data: 0.0452  max mem: 12013\n",
      "Test:  [ 20/500]  eta: 0:02:51  batch_time: 0.3212 (0.3326)  time: 0.3274  data: 0.0010  max mem: 12013\n",
      "Test:  [ 30/500]  eta: 0:02:42  batch_time: 0.3045 (0.3282)  time: 0.3283  data: 0.0007  max mem: 12013\n",
      "Test:  [ 40/500]  eta: 0:02:36  batch_time: 0.3125 (0.3259)  time: 0.3206  data: 0.0005  max mem: 12013\n",
      "Test:  [ 50/500]  eta: 0:02:35  batch_time: 0.3284 (0.3344)  time: 0.3462  data: 0.0009  max mem: 12013\n",
      "Test:  [ 60/500]  eta: 0:02:29  batch_time: 0.3284 (0.3306)  time: 0.3425  data: 0.0009  max mem: 12013\n",
      "Test:  [ 70/500]  eta: 0:02:26  batch_time: 0.3377 (0.3317)  time: 0.3267  data: 0.0009  max mem: 12013\n",
      "Test:  [ 80/500]  eta: 0:02:22  batch_time: 0.3426 (0.3307)  time: 0.3329  data: 0.0009  max mem: 12013\n",
      "Test:  [ 90/500]  eta: 0:02:17  batch_time: 0.3275 (0.3288)  time: 0.3206  data: 0.0009  max mem: 12013\n",
      "Test:  [100/500]  eta: 0:02:14  batch_time: 0.3208 (0.3295)  time: 0.3266  data: 0.0009  max mem: 12013\n",
      "Test:  [110/500]  eta: 0:02:10  batch_time: 0.3036 (0.3277)  time: 0.3246  data: 0.0009  max mem: 12013\n",
      "Test:  [120/500]  eta: 0:02:06  batch_time: 0.3088 (0.3273)  time: 0.3184  data: 0.0009  max mem: 12013\n",
      "Test:  [130/500]  eta: 0:02:03  batch_time: 0.3363 (0.3273)  time: 0.3273  data: 0.0009  max mem: 12013\n",
      "Test:  [140/500]  eta: 0:02:00  batch_time: 0.3356 (0.3288)  time: 0.3401  data: 0.0009  max mem: 12013\n",
      "Test:  [150/500]  eta: 0:01:56  batch_time: 0.3063 (0.3280)  time: 0.3345  data: 0.0009  max mem: 12013\n",
      "Test:  [160/500]  eta: 0:01:52  batch_time: 0.3028 (0.3260)  time: 0.3088  data: 0.0009  max mem: 12013\n",
      "Test:  [170/500]  eta: 0:01:49  batch_time: 0.3048 (0.3258)  time: 0.3115  data: 0.0009  max mem: 12013\n",
      "Test:  [180/500]  eta: 0:01:45  batch_time: 0.3086 (0.3255)  time: 0.3231  data: 0.0009  max mem: 12013\n",
      "Test:  [190/500]  eta: 0:01:42  batch_time: 0.3086 (0.3248)  time: 0.3186  data: 0.0009  max mem: 12013\n",
      "Test:  [200/500]  eta: 0:01:38  batch_time: 0.3057 (0.3251)  time: 0.3239  data: 0.0009  max mem: 12013\n",
      "Test:  [210/500]  eta: 0:01:35  batch_time: 0.3057 (0.3249)  time: 0.3277  data: 0.0009  max mem: 12013\n",
      "Test:  [220/500]  eta: 0:01:32  batch_time: 0.3054 (0.3243)  time: 0.3187  data: 0.0009  max mem: 12013\n",
      "Test:  [230/500]  eta: 0:01:28  batch_time: 0.2994 (0.3242)  time: 0.3192  data: 0.0009  max mem: 12013\n",
      "Test:  [240/500]  eta: 0:01:25  batch_time: 0.3182 (0.3252)  time: 0.3367  data: 0.0009  max mem: 12013\n",
      "Test:  [250/500]  eta: 0:01:22  batch_time: 0.3420 (0.3257)  time: 0.3456  data: 0.0009  max mem: 12013\n",
      "Test:  [260/500]  eta: 0:01:19  batch_time: 0.3360 (0.3261)  time: 0.3391  data: 0.0009  max mem: 12013\n",
      "Test:  [270/500]  eta: 0:01:15  batch_time: 0.3321 (0.3265)  time: 0.3385  data: 0.0009  max mem: 12013\n",
      "Test:  [280/500]  eta: 0:01:12  batch_time: 0.3408 (0.3266)  time: 0.3361  data: 0.0009  max mem: 12013\n",
      "Test:  [290/500]  eta: 0:01:09  batch_time: 0.3393 (0.3267)  time: 0.3313  data: 0.0009  max mem: 12013\n",
      "Test:  [300/500]  eta: 0:01:06  batch_time: 0.3393 (0.3273)  time: 0.3383  data: 0.0009  max mem: 12013\n",
      "Test:  [310/500]  eta: 0:01:02  batch_time: 0.3383 (0.3272)  time: 0.3363  data: 0.0009  max mem: 12013\n",
      "Test:  [320/500]  eta: 0:00:59  batch_time: 0.3221 (0.3274)  time: 0.3324  data: 0.0009  max mem: 12013\n",
      "Test:  [330/500]  eta: 0:00:56  batch_time: 0.3113 (0.3271)  time: 0.3288  data: 0.0009  max mem: 12013\n",
      "Test:  [340/500]  eta: 0:00:52  batch_time: 0.3098 (0.3275)  time: 0.3298  data: 0.0009  max mem: 12013\n",
      "Test:  [350/500]  eta: 0:00:49  batch_time: 0.3197 (0.3271)  time: 0.3278  data: 0.0009  max mem: 12013\n",
      "Test:  [360/500]  eta: 0:00:46  batch_time: 0.3033 (0.3265)  time: 0.3124  data: 0.0009  max mem: 12013\n",
      "Test:  [370/500]  eta: 0:00:42  batch_time: 0.3033 (0.3267)  time: 0.3218  data: 0.0009  max mem: 12013\n",
      "Test:  [380/500]  eta: 0:00:39  batch_time: 0.3353 (0.3270)  time: 0.3380  data: 0.0009  max mem: 12013\n",
      "Test:  [390/500]  eta: 0:00:36  batch_time: 0.3151 (0.3267)  time: 0.3294  data: 0.0009  max mem: 12013\n",
      "Test:  [400/500]  eta: 0:00:33  batch_time: 0.3357 (0.3267)  time: 0.3226  data: 0.0009  max mem: 12013\n",
      "Test:  [410/500]  eta: 0:00:29  batch_time: 0.3191 (0.3267)  time: 0.3291  data: 0.0009  max mem: 12013\n",
      "Test:  [420/500]  eta: 0:00:26  batch_time: 0.3080 (0.3275)  time: 0.3466  data: 0.0009  max mem: 12013\n",
      "Test:  [430/500]  eta: 0:00:23  batch_time: 0.3377 (0.3275)  time: 0.3458  data: 0.0009  max mem: 12013\n",
      "Test:  [440/500]  eta: 0:00:19  batch_time: 0.3183 (0.3282)  time: 0.3450  data: 0.0009  max mem: 12013\n",
      "Test:  [450/500]  eta: 0:00:16  batch_time: 0.3343 (0.3282)  time: 0.3457  data: 0.0009  max mem: 12013\n",
      "Test:  [460/500]  eta: 0:00:13  batch_time: 0.3232 (0.3280)  time: 0.3263  data: 0.0009  max mem: 12013\n",
      "Test:  [470/500]  eta: 0:00:09  batch_time: 0.3375 (0.3282)  time: 0.3302  data: 0.0009  max mem: 12013\n",
      "Test:  [480/500]  eta: 0:00:06  batch_time: 0.3355 (0.3277)  time: 0.3217  data: 0.0009  max mem: 12013\n",
      "Test:  [490/500]  eta: 0:00:03  batch_time: 0.3341 (0.3280)  time: 0.3258  data: 0.0009  max mem: 12013\n",
      "Test: Total time: 0:02:45\n",
      "Latency: 0.3281 sec/batch\n",
      "Throughput: 3.02 samples/sec\n",
      "global correct: 91.4\n",
      "average row correct: ['93.0', '78.5', '84.9', '64.3', '56.5', '61.8', '81.2', '86.4', '95.4', '62.1', '58.1', '77.9', '92.3', '80.5', '87.9', '91.4', '63.3', '92.2', '68.5', '82.8', '68.7']\n",
      "IoU: ['90.1', '75.7', '63.7', '46.0', '51.4', '55.2', '76.3', '74.1', '82.9', '48.0', '55.8', '35.2', '74.7', '73.5', '79.7', '82.6', '31.2', '78.1', '47.1', '78.3', '63.2']\n",
      "mean IoU: 64.9\n",
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hflabs/bot/DeepSchool/speed_up_nn/hw_03/deeplab_quantization_ready/utils.py:295: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 0/32]  eta: 0:09:49  batch_time: 14.9917 (14.9917)  time: 18.4106  data: 3.4188  max mem: 12013\n",
      "Test:  [10/32]  eta: 0:04:23  batch_time: 10.6069 (11.6406)  time: 11.9851  data: 0.3113  max mem: 12013\n",
      "Test:  [20/32]  eta: 0:02:11  batch_time: 10.1415 (10.7310)  time: 10.5540  data: 0.0007  max mem: 12013\n",
      "Test:  [30/32]  eta: 0:00:21  batch_time: 9.4150 (10.5005)  time: 9.9081  data: 0.0006  max mem: 12013\n",
      "Test: Total time: 0:05:32\n",
      "Latency: 10.2317 sec/batch\n",
      "Throughput: 1.51 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.6', '92.3', '86.4', '84.7', '15.3', '76.8', '87.5', '70.2', '82.7', '38.2', '87.1', '56.5', '69.6', '90.1', '85.3', '90.2', '64.4', '88.2', '71.2', '66.4', '60.8']\n",
      "IoU: ['92.6', '83.7', '68.2', '75.2', '14.9', '60.7', '81.4', '53.2', '70.0', '31.0', '79.0', '37.6', '49.5', '80.2', '77.7', '81.9', '46.4', '78.9', '56.9', '62.6', '53.8']\n",
      "mean IoU: 63.6\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "087a60bf-6fb1-4b14-b44e-d06efb9c9f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T18:08:52.752886Z",
     "start_time": "2025-03-03T17:49:55.878830Z"
    }
   },
   "source": [
    "# Замерим скорость оригинальной модели на CPU\n",
    "confmat_original_batch = evaluate(model.cpu(), subset_16batch, device='cpu', num_classes=num_classes)\n",
    "print(confmat_original_batch)\n",
    "# У меня на intel i9 при батчсайзе 32 получился x2 буст"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/32]  eta: 0:27:39  batch_time: 48.6258 (48.6258)  time: 51.8678  data: 3.2419  max mem: 12013\n",
      "Test:  [10/32]  eta: 0:14:55  batch_time: 36.4321 (40.3779)  time: 40.7074  data: 0.2954  max mem: 12013\n",
      "Test:  [20/32]  eta: 0:07:28  batch_time: 34.8171 (37.1569)  time: 36.6203  data: 0.0007  max mem: 12013\n",
      "Test:  [30/32]  eta: 0:01:12  batch_time: 32.4484 (36.3104)  time: 34.1087  data: 0.0006  max mem: 12013\n",
      "Test: Total time: 0:18:56\n",
      "Latency: 35.3861 sec/batch\n",
      "Throughput: 0.44 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.3', '92.9', '86.6', '85.0', '15.5', '77.6', '88.0', '71.0', '82.0', '39.9', '86.5', '59.5', '70.5', '90.2', '86.7', '90.6', '67.0', '88.5', '71.6', '66.2', '61.1']\n",
      "IoU: ['92.6', '82.8', '68.0', '75.9', '15.1', '60.1', '81.2', '53.3', '69.8', '31.7', '79.1', '38.4', '49.9', '79.7', '78.3', '82.0', '48.2', '78.5', '55.7', '61.5', '54.0']\n",
      "mean IoU: 63.6\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "b3e66e00-55a3-4ddf-b376-07e402ff9bbe",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T18:19:21.575140Z",
     "start_time": "2025-03-03T18:08:52.754064Z"
    }
   },
   "source": [
    "# Посчитаем метрики квантованной модели\n",
    "# У меня была просадка где-то до 65 IoU\n",
    "q_model.cpu()\n",
    "confmat = evaluate(q_model, subset, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n",
      "Test:  [ 0/63]  eta: 0:14:31  batch_time: 10.5986 (10.5986)  time: 13.8304  data: 3.2316  max mem: 12013\n",
      "Test:  [10/63]  eta: 0:09:07  batch_time: 10.2706 (10.0009)  time: 10.3261  data: 0.2941  max mem: 12013\n",
      "Test:  [20/63]  eta: 0:08:08  batch_time: 10.2907 (11.1660)  time: 11.2325  data: 0.0008  max mem: 12013\n",
      "Test:  [30/63]  eta: 0:05:56  batch_time: 9.5196 (10.6614)  time: 11.0645  data: 0.0007  max mem: 12013\n",
      "Test:  [40/63]  eta: 0:03:59  batch_time: 8.9075 (10.3123)  time: 9.4501  data: 0.0005  max mem: 12013\n",
      "Test:  [50/63]  eta: 0:02:13  batch_time: 9.0070 (10.1584)  time: 9.4104  data: 0.0009  max mem: 12013\n",
      "Test:  [60/63]  eta: 0:00:30  batch_time: 8.6819 (9.9656)  time: 9.2860  data: 0.0009  max mem: 12013\n",
      "Test: Total time: 0:10:28\n",
      "Latency: 9.8939 sec/batch\n",
      "Throughput: 1.59 samples/sec\n",
      "global correct: 93.3\n",
      "average row correct: ['96.6', '87.6', '79.1', '57.6', '51.2', '58.3', '78.5', '63.7', '90.6', '33.9', '88.5', '53.0', '83.1', '87.3', '84.9', '89.8', '48.4', '81.3', '51.9', '95.1', '70.0']\n",
      "IoU: ['92.3', '67.1', '68.9', '46.6', '43.9', '50.4', '73.9', '54.2', '78.4', '27.9', '75.1', '38.4', '69.5', '79.0', '78.2', '81.5', '29.3', '68.4', '44.5', '91.0', '65.8']\n",
      "mean IoU: 63.1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ef8e149e-08b7-4f90-b3a7-e312adb6ece8",
   "metadata": {},
   "source": [
    "### Делаем Quantization Aware Training. Используем готовый трейнплуп от pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de375f28-bf82-4c3a-924d-03c3a75376e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Делаем фейк квантование, идём смотреть quantization_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6d85d-82cc-4d99-81de-3d12a9e6e375",
   "metadata": {},
   "source": [
    "### Тут берём из train.py скрипт main() и вытаскиваем трейн луп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d671589-a9e9-4459-a59a-b4cea6f653b5",
   "metadata": {},
   "source": [
    "1. Не забыть провалидировать модель fake quant до qat\n",
    "2. Не забыть провалидировать модель после обучения\n",
    "3. Конвертировать модель из fake quant в обычный quant\n",
    "4. Проверить точность и скорость модели\n",
    "Должно хватить пары эпох, lr надо будет покрутить.\n",
    "Цель минимум это поднять точность конвертированной QAT модели (будет у вас QAT до обучения 55, станет 56, молодцы!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8b72c-76c2-4480-a1b1-8f7ee33e5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсказка, учить надо в train и на GPU\n",
    "qat_model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa71d29-c5bf-47fd-9d62-593345f76cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инференс делаем на cpu, предварительно конвертируя модельку на CPU\n",
    "qat_model.cpu()\n",
    "int_qat_model = convert_fx(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e30de-5a6a-45a2-bf7e-27b6ac3c9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность модели fake quant и квантованной после конвертации будут разные\n",
    "# Так и должно быть, всё таки мы эмулировали квантование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3213cc-9a38-44dd-a35e-f4f0f79db8bb",
   "metadata": {},
   "source": [
    "### Балуемся с дистилляцией\n",
    "Врываемся в train.py и добавляем туда дистилляцию, просто по последнему слою (до софтмакса, на логитах) делаем стягивание по MSE\n",
    "\n",
    "Цель поднять точность и ускорить сходимость.\n",
    "\n",
    "Балуемся с весами обычного и distill лосса.\n",
    "\n",
    "Можно вообще выкинуть classification loss и смоделировать ситуацию когда вам не выдали лейблов (жиза)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f1a2f-76c2-48d5-ac99-040460da12a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
